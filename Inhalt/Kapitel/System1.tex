\chapter{Realisierung mit Postgres-XL}
\label{chapter:postgresxl}

\section{Verwendung}
%Indexstrukturen nicht vergessen!
%Mehrrechner-Datenbanksystem?
%replikationsverfahren wichtig?
%auf Fehlen von Triggern eingehen

\subsection{Installation}
%mit Systemvoraussetzungen
\subsubsection{Systemvoraussetzungen}
Die Dokumentation\footnote{\url{http://files.postgres-xl.org/documentation/install-requirements.html}} verwendet hierbei deckungsgleich die offizielle Dokumentation zu den Systemanforderungen von PostgreSQL\footnote{\url{http://www.postgresql.org/docs/9.2/static/install-requirements.html}}.
Dabei wird ein Linux Betriebssystem, 155MB freien Festplattenspeicher für die Übersetzung, Installation und Erstellung eines leeren Datenbankclusters sowie eine Menge von Paketen genannt.
Diese ist: GNU make, gcc, tar und zlib als benötigte sowie libperl oder libpython als optionale Pakete.
Zusätzlich werden für die Erzeugung der Dokumentation oder über Übersetzung des Quellcodes weitere Pakete benötigt.
Diese Anforderungen setzen eine Standard Installation voraus.
Neben Linux Derivaten wird auch FreeBSD und Max OS X unterstützt.
Die Prozessorarchitektur von Intel wird unterstützt, andere sind laut Dokumentation ebenso verwendbar.
Im Rahmen dieser Arbeit konnte Postgres-XL auch auf einem Raspberry Pi 1 Model B, basierend auf einem ARMv6 Prozessor und dem Linux Derivat Raspbian, übersetzt und verwendet werden.

\subsubsection{Installation}
Postgres-XL steht als RPM und direkt als Quellcode bereit.
Davon verfügbare RPM Pakete sind jedoch von Mai 2014 und somit veraltet.
Im Rahmen dieser Arbeit wurde der aktuelle Quellcode von github verwendet.
Die Übersetzung des Quellcodes erfolgt mit einer im Linux Umfeld oft verwendeten configure, make und make install Routine.
Der aktuelle Quellcode wird mit dem Kommandozeilen- und Versionsverwaltungstool git auf den Computer geladen und die darin enthaltene Datei configure mit zusätzlichen Parametern zum Zwecke der Einrichtung der anschließenden Installation ausgeführt.
Die Ausführung von make übersetzt den Quellcode und der Parameter install kopiert die Übersetzungen in die mit configure festgelegten Ordner.
Im Anhang \ref{appendix:install} ist das Skript zur Installation von Postgres-XL auf dem Testsystem zu sehen.
Das Installationsskript muss für andere Systemumgebungen angepasst werden, da Pfade und notwendige Pakete unterschiedlich sein können.
Weiterhin ist zu erwähnen, dass Änderungen an der Kernel-Konfiguration vorzunehmen  sind, jedoch ebenso abhängig von der Systemumgebung.
Im Testsystem musste der Wert des für jede Anwendung nutzbaren geteilten Speichers erhöht werden, um Postgres-XL starten zu können.\\
Um das Kommandozeilentool pgxc\_{}ctl nutzen zu können, muss im Quellcode Ordner in ./contrib/pgxc\_{}ctl gewechselt und dort make sowie make install ausgeführt werden. damit wird das Tool übersetzt und in den in der vorangegangenen Installation festgelegten Ordner kopiert.

\subsubsection{Einrichtung}
Postgres-Xl ist für den Einsatz in einem Cluster konzipiert.
So muss die Installation für jeden Knoten vorgenommen werden.
Die Einrichtung der einzelnen Knoten variiert je nach Art des Knotens, wobei ein Knoten entweder eine GTM Instanz oder mehrere Coordinator sowie DataNodes Instanzen mit einer GTM-Proxy Instanz enthält.
Jede Instanz kann automatisiert mit pgxc\_{}ctl oder manuell erstellt und konfiguriert werden.
Das Testsystem wurde mit pgxc\_{}ctl eingerichtet.
Voraussetzung der Nutzung von pgxc\_{}ctl ist der Zugang zu allen Knoten per SSH ohne Passwortabfrage für den selben Benutzer und die Vergabe eindeutiger Hostnames an die Knoten.
Ist dies gegeben, kann pgxc\_{}ctl in der Kommandozeile gestartet werden.
Mit dem Kommando \textit{prepare config} erzeugt pgxc\_{}ctl eine Konfigurationsdatei unter dem in der Umgebungsvariable PGXC\_{}CTL\_{}HOME festgelegten Ordner.
In dieser Datei werden alle Elemente des Clusters definiert.
Dazu zählt: GTM, GTM-Proxys, Coordinators und DataNodes.
Außerdem können zu allen vier Typen Slaves definiert werden, welche bei Ausfall des Elementes dessen Aufgaben übernehmen.
So wird pro Element das Arbeitsverzeichnis, der Name, der Host, der Port, optionale Konfigurationsparameter, pg\_{}hba Einträge, pgPool Port und der Ordner der Logdateien festgelegt.
Eine detaillierte Beschreibung befindet sich in der Dokumentation.\footnote{\url{http://files.postgres-xl.org/documentation/pgxc-ctl.html}}
Anhang \ref{appendix:pgxcctlconfig} enthält eine beispielhafte Konfigurationsdatei.
%schlussendliche Konfigurationdatei mit aufführen

\subsection{Schnittstelle}
\label{subsection:interface}
%Datenimport gehört dazu
Der Zugriff auf Daten eines Postgres-XL Clusters erfolgt über die Coordinators.
Dazu sind Programme und Tools aus dem PostgreSQL Umfeld zu verwenden.
Dazu zählen \Gls{jdbc}, das Kommandozeilentool psql und das grafische Programm zur Datenbankverwaltung pgAdminIII.
Ebenso sind die SQL Befehle bis auf ein paar Ausnahmen deckungsgleich.
Diese Ausnahmen beziehen sich auf die Verteilung der Daten und Verwaltung des Clusters.
Beispielsweise das SQL Statement \textit{Create Table tblname (serial id, text data) Distributed by Hash(id);} weicht durch die Ergänzung \textit{Distributed by} vom PostgreSQL SQL Syntax ab.
Jede Tabelle wird in jeder PostgreSQL Instanz erzeugt.
Dabei werden die Daten entweder nach einem Attribut verteilt oder zwischen den Datenbankinstanzen gespiegelt.
Das Schlüsselwort \textit{Distributed} veranlasst eine Verteilung der Daten, \textit{Replicate} dagegen eine Replikation der Tabelle über alle Nodes.
Weiterhin zu erwähnen ist der Befehl \textit{Create Node nodename With (TYPE=, HOST=, PORT=)}, welcher direkt als SQL Statement verwendet werden kann und dem Cluster einen Knoten hinzufügt.
Analog dazu existiert der Befehl \textit{Drop Node nodename} zum entfernen eines Knotens.
Wurde das Cluster verändert, ist dies mit \textit{Select * From pgxc\_{}pool\_{}reload();} für alle Knoten zu propagieren.
Weitere Abweichungen sind der Dokumentation zu entnehmen.\footnote{siehe \url{http://files.postgres-xl.org/documentation/sql-commands.html}}

Daten wurden mit dem Kommandozeilentool pg\_{}dump aus dem Ist-Stand in das Testsystem überführt.
Der Ist-Zustand verwendet PostgreSQL Version 9.3.
Um Daten zwischen verschiedenen Versionen auszutauschen, muss der Zwischenstand der Datenbank im Textformat erstellt und dieser angepasst als SQL Anweisungen in das andere System eingespielt werden.
%zu langsam
Ein Datenaustausch mit der SQL Anweisung \textit{Copy} oder der Erweiterung DBLink ist ebenso möglich.
Diese Kompatibilität wird als erfüllter Funktionstest des Datenaustausches gewertet.

%DBLink -> Kombatibiltätsprobleme? nicht festgestellt
%Übertragung im Prototyp???

%psql -c "copy (select list of column  from table_name ) to stdin " dbanme | psql -c "table_name(specify the column ) from stdout " targetDB
%https://stackoverflow.com/questions/14797327/copy-data-between-two-tables-in-postgresql-using-dblink-sql

\subsection{Verarbeitung}
%SQL
%PL/R
%R -> auf welchen Knoten wird das ausgeführt? Coordinator?
%PostGIS
Die Datenverarbeitung erfolgt analog des Ist-Standes bei Agri~Con.
Mit der Installation\footnote{Skript siehe \ref{appendix:postgis}} von PostGIS als Erweiterung, können die vorhandenen SQL Funktionen übernommen werden, ebenso die R Bibliotheken des speziellen Krigings.
Dafür ist neben R als Programmiersprache mit notwendigen Paketen auf den Systemen, Pl/R als Erweiterung in Postgres-XL, zu installieren.
Die Installation von Pl/R mit dem Quellcode als Grundlage ist in Anhang \ref{appendix:plr} zu finden.

%\section{Prototyp}
%ERM festhalten

\section{Entwurf}
%Übernahme des Schemas
%spezielle Daten werden übernommen -> vllt. replikation möglich?
%eine Idee: quelldaten (punkte) in pgxc schreiben, dort Verarbeitung starten und Ergebnis auf pg kopieren
%zwei Datenquellen in Programmen ist kompliziert, server in pg nimmt performanz?
%vollständige Umstellung auf pgxc kann zu kombatibilitätsproblemen führen (Funktionen) und replikation zu hetzner wird schwierig

%Überlegen, ob konkreter Prototyp nicht zu kompliziert ist, und man stattdessen eine allgemeine Aussage zur Leistungsfähigkeit gegenüber PostgreSQL  trift

%welche Funktionen benötigen Daten aus beiden DBs?
%Gibt es Quelldaten die nur verarbeitet und nicht direkt gelesen werden?
%Die Replikation zu Hetzner mit berücksichtigen?
%Mail Service  -> existiert eine Übersicht?
%Maßnahmen Service?

\section{Implementierung}
%SQL mit dblnk skizzieren

\section{Tests}
%pgbench http://www.postgresql.org/docs/devel/static/pgbench.html
Die systematischen Tests werden in diesem Kapitel vorgestellt.
Die Kriterien wurden in Kapitel \ref{qualitätsmetriken} definiert, somit werden hier die Randbedingungen, Eingaben und Ergebnisse dargelegt.

\subsection{Testumgebung}
Die wesentliche Randbedingung Testumgebung wurde nach der Softwareauswahl und vor der Durchführung der Tests erstellt.
Da es sich bei dieser Umgebung nicht um aktuelle Hardware handelt, sind einzig relative Aussagen der Leistung treffbar.
Der Cluster wird mit Virtualisierung erstellt.
Dafür steht ein IBM Rack Server x3850 M2 zur Verfügung, mit folgender Ausstattung:
vier Xeon E7330 Quad-Core mit 2,4 GHz, 32GB DDR2 RAM, vier 500GB 2,5 Zoll SATA Festplatten von Western Digital mit 7.200 U/min und einem MR10k Raid-Controller.
Als Virtualisierungssoftware kommt \Gls{esxi} in der kostenlosen Version 5.5 mit \Gls{vsphere} 6 als Testversion zum Einsatz.
Mit dieser Virtualisierungslösung ist es möglich, Ressourcen explizit und ausschließlich einer VM zuzuordnen.
Ziel dieser unter Abbildung \ref{fig:physAufb} skizzierten Testumgebung ist es Postgres-XL mit PostgreSQL des Ist Standes zu vergleichen, einen homogenen Cluster zu erzeugen und Aussagen über die Skalierbarkeit von Postgres-XL zu treffen.
Die Ausstattung des Computers zur Verwaltung der Virtualisierung wird nicht definiert, da dies keinen Einfluss auf Messungen hat.
Die VMs ist in Abbildung \ref{fig:VMAufb} dargestellt.
Typ I enthält eine GTM Instanz und Typ II eine GTM-Proxy, eine Coordinator und zwei DataNode Instanzen.
Dabei stehen sechs Typ II VMs zur Verfügung, wobei zur Beurteilung der Skalierbarkeit zwei bis sieben genutzt werden.
Jede VM besitzt als Betriebssystem Ubuntu 14.04 LTS und alle für die Installation und Ausführung des Prototypen notwendigen Pakete.
Weiterhin erhalten die Typ II VMs folgende Hardware Zuordnung:
zwei Prozessorkerne, drei GB RAM und 100 GB Festplattenspeicherplatz.
Typ I erhält dagegen zwei Prozessorkerne, drei GB RAM und 20 GB Festplattenspeicherplatz.
\begin{figure}[h!]
\centering
\input{Abbildungen/Testsystem_physischerAufbau.tex}
\caption[Aufbau der Geräte des Testsystems]{Aufbau der Geräte des Testsystems}
\label{fig:physAufb}
\end{figure}
\begin{figure}[h!]
\centering
\input{Abbildungen/Testsystem_VMs.tex}
\caption[Aufbau der VMs des Testsystems]{Aufbau der VMs des Testsystems}
\label{fig:VMAufb}
\end{figure}

Als Referenzsystem wird ein Ubuntu System mit PostgreSQL, PostGIS und R sowie der Hardwareausstattung einer Typ II VM verwendet.
Dabei kommt PostgreSQL 9.3 und PostGIS 2.1.5 zum Einsatz.
Mit der exakten Übereinstimmung der Ausstattung der VMs ist eine Vergleichbarkeit von PostgreSQL und Postgres-XL gegeben.
Außerdem kann durch Verkleinerung und Vergrößerung des Clusters die Skalierbarkeit von Postgres-XL bewertet werden.

Die physischen Festspeicher des Testservers stehen den VMs nicht exklusiv zur Verfügung.
Die Anzahl an Operationen pro Zeiteinheit auf diesem Medium soll für alle VMs annähernd gleich sein, deswegen wird der feste Speicherbereich der VMs gleichmäßig auf die vier physischen Festplatten verteilt.\footnote{Statische Verteilung, sodass jede physische Festplatte die gleiche Anzahl an virtuellen Festplatten beinhaltet.}
Um die Vergleichbarkeit der zeitlich abhängigen Messwerte zu gewährleisten, wird ESXi als Zeitgeber für alle VMs eingerichtet.

%Überwachung der Systemauslastung?
%Überwachung der logs?

\subsection{Funktionstests}
Die Schnittstellen sind nicht explizit zu testen, da Postgres-XL und PostgreSQL wie in Abschnitt \ref{subsection:interface} demonstriert direkt Daten austauschen können.
%Schnittstellen: PostgreSQL mit dblink demonstrieren; PostGIS: Tabelle mit geometry erzeugen, füllen und Funktionen darauf anwenden; UMN: simples Mapfile für nsensorlogs erstellen

Da beide Systeme PostGIS 2.1.5 verwenden, sind die Austauschformate für geografische Daten identisch.
%Austauschformate: Übertragung der vorhandenen Daten ist beleg

Mit PostGIS kann direkt zwischen den Koordinatenreferenzsystemen umgerechnet werden:\\
\textit{select id, st\_{}astext(st\_{}transform(geom, 3857)) as transformed, st\_{}srid(st\_{}transform(geom, 3857)) as newsrid, st\_{}astext(st\_{}transform(st\_{}transform(geom, 3857), 4326)) as original, st\_{}srid(st\_{}transform(st\_{}transform(geom, 3857), 4326)) as srid from nutrients.samples limit 10;}\\
So werden die Punkte der Tabelle samples im Schema nutrients mit dem EPSG Code 4326 zum EPSG Code 3857 sowie wieder zurück umgerechnet.
%EPSG Codes 4326 und 3857 testen (Zwischen ihnen Umwandeln)


%weitere Funktionen: Schläge miteinander verschneiden (typische Fälle verwenden, mit UMN darstellen?); Geostatistik mit R Bibo zeigen; topologische Filterung?; räumliche Filterung anhand von Fields demonstrieren   <- Immer auf Funktionsdefinition mit Parametern verweisen

\subsection{Leistungstests}
%Ziel ist Vergleich und Aussage über Skalierbarkeit(T(1)/T(p))/Effizienz(S(p)/p)

%historische Daten?
%Wie schnell werden nsensorlogs gespeichert?
%Wie schnell werden nsensorlogs abgerufen?
%Laufzeit Kriging: abhängig nach Distribution - entweder nach geom oder farmid oder fileid

%mit SQL Bordmitteln - pg_bench eventuell zusätzlich um ein paar Aussagen zum cluster overhead zu treffen

%Aggregation
%Query vorbereiten
%Laufzeitmessung testen
%Auslastung messen/testen
%mehrere Durchgänge
%gegenüber stellen