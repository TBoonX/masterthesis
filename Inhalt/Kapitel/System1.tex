\chapter{Realisierung mit Postgres-XL}
\label{chapter:postgresxl}

\section{Verwendung}
%Indexstrukturen nicht vergessen!
%Mehrrechner-Datenbanksystem?
%replikationsverfahren wichtig?
%auf Fehlen von Triggern eingehen

\subsection{Installation}
%mit Systemvoraussetzungen
\subsubsection{Systemvoraussetzungen}
Die Dokumentation\footnote{\url{http://files.postgres-xl.org/documentation/install-requirements.html}} verwendet hierbei deckungsgleich die offizielle Dokumentation zu den Systemanforderungen von PostgreSQL\footnote{\url{http://www.postgresql.org/docs/9.2/static/install-requirements.html}}.
Dabei wird ein Linux Betriebssystem, 155MB freien Festplattenspeicher für die Übersetzung, Installation und Erstellung eines leeren Datenbankclusters sowie eine Menge von Paketen genannt.
Diese ist: GNU make, gcc, tar und zlib als benötigte sowie libperl oder libpython als optionale Pakete.
Zusätzlich werden für die Erzeugung der Dokumentation oder über Übersetzung des Quellcodes weitere Pakete benötigt.
Diese Anforderungen setzen eine Standard Installation voraus.
Neben Linux Derivaten wird auch FreeBSD und Max OS X unterstützt.
Die Prozessorarchitektur von Intel wird unterstützt, andere sind laut Dokumentation ebenso verwendbar.
Im Rahmen dieser Arbeit konnte Postgres-XL auch auf einem Raspberry Pi 1 Model B, basierend auf einem ARMv6 Prozessor und dem Linux Derivat Raspbian, installiert und verwendet werden.

\subsubsection{Installation}
Postgres-XL steht als RPM und direkt als Quellcode bereit.
Davon verfügbare RPM Pakete sind jedoch von Mai 2014 und somit veraltet.
Im Rahmen dieser Arbeit wurde der aktuelle Quellcode von github verwendet.
Die Übersetzung des Quellcodes erfolgt mit einer im Linux Umfeld oft verwendeten configure, make und make install Routine.
Der aktuelle Quellcode wird mit dem Kommandozeilen- und Versionsverwaltungstool git auf den Computer geladen und die darin enthaltene Datei configure mit zusätzlichen Parametern zum Zwecke der Einrichtung der anschließenden Installation ausgeführt.
Die Ausführung von make übersetzt den Quellcode und der Parameter install kopiert die Übersetzungen in die mit configure festgelegten Ordner.
Im Anhang \ref{appendix:install} ist das Skript zur Installation von Postgres-XL auf dem Testsystem zu sehen.
Das Installationsskript muss für andere Systemumgebungen angepasst werden, da Pfade und notwendige Pakete unterschiedlich sein können.
Weiterhin ist zu erwähnen, dass Änderungen an der Kernel-Konfiguration vorzunehmen  sind, jedoch ebenso abhängig von der Systemumgebung.
Im Testsystem musste der Wert des für jede Anwendung nutzbaren geteilten Speichers erhöht werden, um PostgreSQL starten zu können.\\
Um das Kommandozeilentool pgxc\_{}ctl nutzen zu können, muss im Quellcode Ordner in ./contrib/pgxc\_{}ctl gewechselt und dort make sowie make install ausgeführt werden. damit wird das Tool übersetzt und in den in der vorangegangenen Installation festgelegten Ordner kopiert.

\subsubsection{Einrichtung}
Postgres-Xl ist für den Einsatz in einem Cluster konzipiert.
So muss die Installation für jeden Knoten vorgenommen werden.
Die Einrichtung der einzelnen Knoten variiert je nach Art des Knotens, wobei ein Knoten entweder eine GTM Instanz oder mehrere Coordinator sowie DataNodes Instanzen mit einer GTM-Proxy Instanz enthält.
Jede Instanz kann automatisiert mit pgxc\_{}ctl oder manuell erstellt und konfiguriert werden.
Das Testsystem wurde mit pgxc\_{}ctl eingerichtet.
Voraussetzung der Nutzung von pgxc\_{}ctl ist der Zugang zu allen Knoten per SSH ohne Passwortabfrage für den selben Benutzer und die Vergabe eindeutiger Hostnames an die Knoten.
Ist dies gegeben, kann pgxc\_{}ctl in der Kommandozeile gestartet werden.
Mit dem Kommando \textit{prepare config} erzeugt pgxc\_{}ctl eine Konfigurationsdatei unter dem in der Umgebungsvariable PGXC\_{}CTL\_{}HOME festgelegten Ordner.
In dieser Datei werden alle Elemente des Clusters definiert.
Dazu zählt: GTM, GTM-Proxys, Coordinators und DataNodes.
Außerdem können zu allen vier Typen Slaves definiert werden, welche bei Ausfall des Elementes dessen Aufgaben übernehmen.
So wird pro Element das Arbeitsverzeichnis, der Name, der Host, der Port, optionale Konfigurationsparameter, pg\_{}hba Einträge, pgPool Port und der Ordner der Logdateien festgelegt.
Eine detaillierte Beschreibung befindet sich in der Dokumentation.\footnote{\url{http://files.postgres-xl.org/documentation/pgxc-ctl.html}}
Anhang \ref{appendix:pgxcctlconfig} enthält eine beispielhafte Konfigurationsdatei.
%schlussendliche Konfigurationdatei mit aufführen

\subsection{Schnittstelle}
%Datenimport gehört dazu
Der Zugriff auf Daten eines Postgres-XL Clusters erfolgt über die Coordinators.
Dazu sind Programme und Tools aus dem PostgreSQL Umfeld zu verwenden.
Dazu zählen \Gls{jdbc}, das Kommandozeilentool psql und das grafische Programm zur Datenbankverwaltung pgAdminIII.
Ebenso sind die SQL Befehle bis auf ein paar Ausnahmen deckungsgleich.
Diese Ausnahmen beziehen sich auf die Verteilung der Daten und Verwaltung des Clusters.
Beispielsweise das SQL Statement \textit{Create Table tblname (serial id, text data) Distributed by Hash(id);} weicht durch die Ergänzung \textit{Distributed by} vom PostgreSQL SQL Syntax ab.
Jede Tabelle wird in jeder PostgreSQL Instanz erzeugt.
Dabei werden die Daten entweder nach einem Attribut verteilt oder zwischen den Datenbankinstanzen gespiegelt.
Das Schlüsselwort \textit{Distributed} veranlasst eine Verteilung der Daten, \textit{Replicate} dagegen eine Replikation der Tabelle über alle Nodes.
Weiterhin zu erwähnen ist der Befehl \textit{Create Node nodename With (TYPE=, HOST=, PORT=)}, welcher direkt als SQL Statement verwendet werden kann und dem Cluster einen Knoten hinzufügt.
Analog dazu existiert der Befehl \textit{Drop Node nodename} zum entfernen eines Knotens.
Wurde das Cluster verändert, ist dies mit \textit{Select * From pgxc\_{}pool\_{}reload();} für alle Knoten zu propagieren.
Weitere Abweichungen sind der Dokumentation zu entnehmen.\footnote{siehe \url{http://files.postgres-xl.org/documentation/sql-commands.html}}

Daten wurden mit dem Kommandozeilentool pg\_{}dump aus dem Ist-Stand in das Testsystem überführt.
Der Ist-Zustand verwendet PostgreSQL Version 9.3.
Um Daten zwischen verschiedenen Versionen auszutauschen, muss der Zwischenstand der Datenbank im Textformat erstellt und dieser angepasst als SQL Anweisungen in das andere System eingespielt werden.

%DBLink -> Kombatibiltätsprobleme? nicht festgestellt
%Übertragung im Prototyp???

%psql -c "copy (select list of column  from table_name ) to stdin " dbanme | psql -c "table_name(specify the column ) from stdout " targetDB
%https://stackoverflow.com/questions/14797327/copy-data-between-two-tables-in-postgresql-using-dblink-sql

\subsection{Verarbeitung}
%SQL
%PL/R
%R -> auf welchen Knoten wird das ausgeführt? Coordinator?
%PostGIS
Die Datenverarbeitung erfolgt analog des Ist-Standes bei Agri~Con.
Mit der Installation\footnote{Skript siehe \ref{appendix:postgis}} von PostGIS als Erweiterung, können die vorhandenen SQL Funktionen übernommen werden, ebenso die R Bibliotheken des speziellen Krigings.
Dafür ist neben R als Programmiersprache auf den Systemen, Pl/R als Erweiterung in Postgres-XL, zu installieren.
Die Installation von Pl/R mit dem Quellcode als Grundlage ist in Anhang \ref{appendix:plr} zu finden.

%\section{Prototyp}
%ERM festhalten

\section{Entwurf}
%Übernahme des Schemas
%spezielle Daten werden übernommen -> vllt. replikation möglich?
%eine Idee: quelldaten (punkte) in pgxc schreiben, dort Verarbeitung starten und Ergebnis auf pg kopieren
%zwei Datenquellen in Programmen ist kompliziert, server in pg nimmt performanz?
%vollständige Umstellung auf pgxc kann zu kombatibilitätsproblemen führen (Funktionen) und replikation zu hetzner wird schwierig

%Überlegen, ob konkreter Prototyp nicht zu kompliziert ist, und man stattdessen eine allgemeine Aussage zur Leistungsfähigkeit gegenüber PostgreSQL  trift

%welche Funktionen benötigen Daten aus beiden DBs?
%Gibt es Quelldaten die nur verarbeitet und nicht direkt gelesen werden?
%Die Replikation zu Hetzner mit berücksichtigen?
%Mail Service  -> existiert eine Übersicht?
%Maßnahmen Service?

\section{Implementierung}
%SQL mit dblnk skizzieren

\section{Tests}
%pgbench http://www.postgresql.org/docs/devel/static/pgbench.html

\subsection{Testumgebung}
Der Cluster wird mit Virtualisierung erstellt.
Dafür steht ein IBM Rack Server x3850 M2 zur Verfügung, mit folgender Ausstattung:
vier Xeon E7330 Quad-Core mit 2,4 GHz, 32GB DDR2 RAM, vier 500GB 2,5 Zoll SATA Festplatten von Western Digital mit 7.200 U/min und einem MR10k Raid-Controller.
Als Virtualisierungssoftware kommt \Gls{esxi} in der kostenlosen Version 5.5 mit \Gls{vsphere} als Testversion 6 zum Einsatz.
Mit dieser Virtualisierungslösung ist es möglich, Ressourcen explizit und ausschließlich einer VM zuzuordnen.
Ziel dieser unter Abbildung \ref{fig:physAufb} dargestellten Testumgebung ist es Postgres-XL mit PostgreSQL des Ist Standes zu vergleichen, einen homogenen Cluster zu erzeugen und Aussagen über die Skalierbarkeit von Postgres-XL zu treffen.
Die VMs sind in Abbildung \ref{fig:VMAufb} dargestellt.
\begin{figure}[h!]
\centering
\input{Abbildungen/Testsystem_physischerAufbau.tex}
\caption[Aufbau Geräte des Testsystems]{Aufbau Geräte des Testsystems}
\label{fig:physAufb}
\end{figure}
\begin{figure}[h!]
\centering
\input{Abbildungen/Testsystem_VMsdia.tex}
\caption[Aufbau VMs des Testsystems]{Aufbau VMs des Testsystems}
\label{fig:VMAufb}
\end{figure}

\subsection{Funktionstests}
%Schnittstellen: PostgreSQL mit dblink demonstrieren; PostGIS: Tabelle mit geometry erzeugen, füllen und Funktionen darauf anwenden; UMN: simples Mapfile für nsensorlogs erstellen
%Austauschformate: Übertragung der vorhandenen Daten ist beleg
%EPSG Codes 4326 und 3857 testen (Zwischen ihnen Umwandeln)
%weitere Funktionen: Schläge miteinander verschneiden (typische Fälle verwenden, mit UMN darstellen?); Geostatistik mit R Bibo zeigen; topologische Filterung?; räumliche Filterung anhand von Fields demonstrieren   <- Immer auf Funktionsdefinition mit Parametern verweisen

\subsection{Leistungstests}
%Ziel ist Vergleich und Aussage über Skalierbarkeit(T(1)/T(p))/Effizienz(S(p)/p)

%historische Daten?
%Wie schnell werden nsensorlogs gespeichert?
%Wie schnell werden nsensorlogs abgerufen?
%Laufzeit Kriging: abhängig nach Distribution - entweder nach geom oder farmid oder fileid

%mit SQL Bordmitteln - pg_bench eventuell zusätzlich um ein paar Aussagen zum cluster overhead zu treffen