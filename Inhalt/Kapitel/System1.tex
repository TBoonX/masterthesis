\chapter{Realisierung mit Postgres-XL}
\label{chapter:postgresxl}

\section{Verwendung}
%Indexstrukturen nicht vergessen!
%Mehrrechner-Datenbanksystem?
%replikationsverfahren wichtig?
%auf Fehlen von Triggern eingehen

Nach der theoretischen Vorstellung des Frameworks im Abschnitt \ref{grundlagen:postgresxl} wird in diesem Unterkapitel die konkrete praktische Verwendung entsprechend den Abschnitten Installation, Schnittstelle und Verarbeitung dargelegt.

\subsection{Installation}
%mit Systemvoraussetzungen
\subsubsection{Systemvoraussetzungen}
Die Dokumentation\footnote{\url{http://files.postgres-xl.org/documentation/install-requirements.html}} verwendet hierbei deckungsgleich die offizielle Dokumentation zu den Systemanforderungen von PostgreSQL\footnote{\url{http://www.postgresql.org/docs/9.2/static/install-requirements.html}}.
Dabei wird ein Linux Betriebssystem, 155MB freien Festplattenspeicher für die Übersetzung, Installation und Erstellung eines leeren Datenbankclusters sowie eine Menge von Paketen genannt.
Diese ist: GNU make, gcc, tar und zlib als benötigte sowie libperl oder libpython als optionale Pakete.
Zusätzlich werden für die Erzeugung der Dokumentation oder über Übersetzung des Quellcodes weitere Pakete benötigt.
Diese Anforderungen setzen eine Standard Installation voraus.
Neben Linux Derivaten wird auch FreeBSD und Max OS X unterstützt.
Die Prozessorarchitektur von Intel wird unterstützt, andere sind laut Dokumentation ebenso verwendbar.
Im Rahmen dieser Arbeit konnte Postgres-XL auch auf einem Raspberry Pi 1 Model B, basierend auf einem ARMv6 Prozessor und dem Linux Derivat Raspbian, übersetzt und verwendet werden.

\subsubsection{Installation}
Postgres-XL steht als RPM und direkt als Quellcode bereit.
Davon verfügbare RPM Pakete sind jedoch von Mai 2014 und somit veraltet.
Im Rahmen dieser Arbeit wurde der aktuelle Quellcode von github verwendet.
Die Übersetzung des Quellcodes erfolgt mit einer im Linux Umfeld oft verwendeten configure, make und make install Routine.
Der aktuelle Quellcode wird mit dem Kommandozeilen- und Versionsverwaltungstool git auf den Computer geladen und die darin enthaltene Datei configure mit zusätzlichen Parametern zum Zwecke der Einrichtung der anschließenden Installation ausgeführt.
Die Ausführung von make übersetzt den Quellcode und der Parameter install kopiert die Übersetzungen in die mit configure festgelegten Ordner.
Im Anhang \ref{appendix:install} ist das Skript zur Installation von Postgres-XL auf dem Testsystem zu sehen.
Das Installationsskript muss für andere Systemumgebungen angepasst werden, da Pfade und notwendige Pakete unterschiedlich sein können.
Weiterhin ist zu erwähnen, dass Änderungen an der Kernel-Konfiguration vorzunehmen  sind, jedoch ebenso abhängig von der Systemumgebung.
Im Testsystem musste der Wert des für jede Anwendung nutzbaren geteilten Speichers erhöht werden, um Postgres-XL starten zu können.\\
Um das Kommandozeilentool pgxc\_{}ctl nutzen zu können, muss im Quellcode Ordner in ./contrib/pgxc\_{}ctl gewechselt und dort make sowie make install ausgeführt werden. damit wird das Tool übersetzt und in den in der vorangegangenen Installation festgelegten Ordner kopiert.

\subsubsection{Einrichtung}
Postgres-Xl ist für den Einsatz in einem Cluster konzipiert.
So muss die Installation für jeden Knoten vorgenommen werden.
Die Einrichtung der einzelnen Knoten variiert je nach Art des Knotens, wobei ein Knoten entweder eine GTM Instanz oder mehrere Coordinator sowie DataNodes Instanzen mit einer GTM-Proxy Instanz enthält.
Jede Instanz kann automatisiert mit pgxc\_{}ctl oder manuell erstellt und konfiguriert werden.
Das Testsystem wurde mit pgxc\_{}ctl eingerichtet.
Voraussetzung der Nutzung von pgxc\_{}ctl ist der Zugang zu allen Knoten per SSH ohne Passwortabfrage für den selben Benutzer und die Vergabe eindeutiger Hostnames an die Knoten.
Ist dies gegeben, kann pgxc\_{}ctl in der Kommandozeile gestartet werden.
Mit dem Kommando \textit{prepare config} erzeugt pgxc\_{}ctl eine Konfigurationsdatei unter dem in der Umgebungsvariable PGXC\_{}CTL\_{}HOME festgelegten Ordner.
In dieser Datei werden alle Elemente des Clusters definiert.
Dazu zählt: GTM, GTM-Proxys, Coordinators und DataNodes.
Außerdem können zu allen vier Typen Slaves definiert werden, welche bei Ausfall des Elementes dessen Aufgaben übernehmen.
So wird pro Element das Arbeitsverzeichnis, der Name, der Host, der Port, optionale Konfigurationsparameter, pg\_{}hba Einträge, pgPool Port und der Ordner der Logdateien festgelegt.
Eine detaillierte Beschreibung befindet sich in der Dokumentation.\footnote{\url{http://files.postgres-xl.org/documentation/pgxc-ctl.html}}
Anhang \ref{appendix:pgxcctlconfig} enthält eine beispielhafte Konfigurationsdatei.
%schlussendliche Konfigurationdatei mit aufführen

\subsection{Schnittstelle}
\label{subsection:interface}
%Datenimport gehört dazu
Der Zugriff auf Daten eines Postgres-XL Clusters erfolgt über die Coordinators.
Dazu sind Programme und Tools aus dem PostgreSQL Umfeld zu verwenden.
Dazu zählen \Gls{jdbc}, das Kommandozeilentool psql und das grafische Programm zur Datenbankverwaltung pgAdminIII.
Ebenso sind die SQL Befehle bis auf ein paar Ausnahmen deckungsgleich.
Diese Ausnahmen beziehen sich auf die Verteilung der Daten und Verwaltung des Clusters.
Beispielsweise das SQL Statement \textit{Create Table tblname (serial id, text data) Distributed by Hash(id);} weicht durch die Ergänzung \textit{Distributed by} vom PostgreSQL SQL Syntax ab.
Jede Tabelle wird in jeder PostgreSQL Instanz erzeugt.
Dabei werden die Daten entweder nach einem Attribut verteilt oder zwischen den Datenbankinstanzen gespiegelt.
Das Schlüsselwort \textit{Distributed} veranlasst eine Verteilung der Daten, \textit{Replicate} dagegen eine Replikation der Tabelle über alle Nodes.
Die unterstützten Datentypen sind der Dokumentation zu entnehmen.
Weiterhin zu erwähnen ist der Befehl \textit{Create Node nodename With (TYPE=, HOST=, PORT=)}, welcher direkt als SQL Statement verwendet werden kann und dem Cluster einen Knoten hinzufügt.
Analog dazu existiert der Befehl \textit{Drop Node nodename} zum entfernen eines Knotens.
Wurde das Cluster verändert, ist dies mit \textit{Select * From pgxc\_{}pool\_{}reload();} für alle Knoten zu propagieren.
Weitere Abweichungen sind der Dokumentation zu entnehmen.\footnote{siehe \url{http://files.postgres-xl.org/documentation/sql-commands.html}}

Das Datenbankschema wurde mit pg\_{}dump in eine Textdatei geladen und als SQL Befehle in Postgres-XL übernommen.
Die Übernahme der Daten erfolgte mit db\_{}link, welches auch zwischen unterschiedlichen PostgreSQL Versionen funktioniert.
%Der Ist-Zustand verwendet PostgreSQL Version 9.3.
Die Daten können auch analog des Schema übertragen werden, dies dauert jedoch auf Grund der Umwandlung von zu zu Textformaten länger.

\subsection{Verarbeitung}
%SQL
%PL/R
%R -> auf welchen Knoten wird das ausgeführt? Coordinator?
%PostGIS
Die Datenverarbeitung erfolgt analog des Ist-Standes bei Agri~Con.
Mit der Installation\footnote{Skript siehe \ref{appendix:postgis}} von PostGIS als Erweiterung, können die vorhandenen SQL Funktionen übernommen werden, ebenso die R Bibliotheken des speziellen Krigings.
Dafür ist neben R als Programmiersprache mit notwendigen Paketen auf den Systemen, Pl/R als Erweiterung in Postgres-XL, zu installieren.
Die Installation von Pl/R mit dem Quellcode als Grundlage ist in Anhang \ref{appendix:plr} zu finden.

%\section{Prototyp}
%ERM festhalten

\section{Entwurf}
Dieses Unterkapitel enthält die Definition des Postgres-XL Prototypen für den Einsatz bei Agri Con.
Als erstes werden die Gründe für diese Art des Entwurfs dargelegt.

Die Erfüllung der Anforderungen liegt bei Postgres-XL auf Grund der Beinhaltens von PostgreSQL bei 86\%{}.
%starke Integration: 2 Möglichkeiten
%Ersetzung
Aus diesem Grund besteht die geeignete Möglichkeit einen Entwurf zu erzeugen, welcher wesentliche Aufgaben des Ist-Standes übernimmt oder den Ist-Stand ersetzt.\\
Gegen eine Ersetzung spricht das Trigger in der aktuellen Postgres-XL Version nicht verwendet werden können.
Zwar können Trigger in Funktionen ausgelagert und bei Verwendung der Tabellen aufgerufen werden, aber dies würde einen erheblichen Implementationsaufwand bedeuten und nicht zu 100\%{} die bestehende Funktionalitäten abbilden.
%Teilintegration
Jedoch ist eine grundlegende Integration in den Ist-Stand notwendig. %warum?
Dies ist in der Datenabhängigkeit der Bestandsdaten und der Eignung von Postgres-XL begründet.
Das Datenbankschema befindet sich in der ersten und zweiten Normalform, wodurch eine Abhängigkeit über Fremdschlüssel zu häufig verwendeten Tabellen wie farm.farms oder farm.fields besteht, was eine Auslagerung von Tabellen und Funktionen nicht trivial macht.
Eine teilweise Schemaintegration mit anschließender Normalisierung der zwei Datenbankschemata würde Änderung aller Programme nach sich ziehen und in diesem Rahmen zu aufwendig ausfallen.\\
Deshalb ist die Erstellung eines umfassenden Entwurfs hinsichtlich des speziellen Szenarios bei Agri~Con im Rahmen dieser Arbeit nicht möglich.
Der Entwurf wird daher als Klon des Ist-Standes, jedoch ohne Trigger, erstellt.
%großer Aufwand für genauen Entwurf, weshalb lieber Aussagen zum Einsatz in diesem Szenario gegeben werden sollen
%Aufwand auch groß da Verteilung, ersatz der Trigger, Änderungen der Primär- und Fremdschlüssel bedacht werden müssen
Entsprechend den Leistungstests soll der Entwurf die Produktivdaten liefern und anwendungsnahe Berechnungen ausführen.
Somit sind Aussagen zur Leistungsfähigkeit gegenüber dem Ist-Stand treffbar.
Die Speicherung von historischen Daten wird aus Zeitgründen nicht betrachtet.
Eine Übernahme aller vorhandenen Daten wurde mit Abschnitt \ref{subsection:interface} erläutert, sodass die Möglichkeit der Speicherung von historischen Daten damit gezeigt ist.

Der Ist-Stand wurde unter Kapitel \ref{IstStand} dargelegt, somit sind die Unterschiede des für die Testumgebung umgesetzten Entwurfes zu erläutern.
Das Datenbankschema unterscheidet sich von dem des Ist-Standes durch das Fehlen von Triggern und einigen Fremdschlüssel Constraints.
Diese Fremdschlüsselbeziehungen müssen entfernt werden, da Primär- und Fremdschlüssel immer in \textit{distribute by} enthalten sein müssen, was entweder auf Grund der Stufe der Datennormalität nicht umsetzbar ist oder diese Beziehungen in den Tests nicht verwendet werden.
Diese Änderungen sind auch im Vergleichssystem mit PostgreSQL 9.3 enthalten.

%\section{Implementierung}
%SQL mit dblnk skizzieren

\section{Tests}
%Erwartung definieren!

%pgbench http://www.postgresql.org/docs/devel/static/pgbench.html
Die systematischen Tests werden in diesem Kapitel vorgestellt.
Die Kriterien wurden in Kapitel \ref{qualitätsmetriken} definiert, somit werden hier die Randbedingungen, Eingaben, Durchführung und Ergebnisse dargelegt.

\subsection{Testumgebung}
Die wesentliche Randbedingung Testumgebung wurde nach der Softwareauswahl und vor der Durchführung der Tests erstellt.
Da es sich bei dieser Umgebung um gebrauchte Hardware aus dem Jahr 2007 handelt, sind einzig relative Aussagen der Leistung treffbar.
Der Cluster wird mit Virtualisierung der einzelnen Knoten erstellt.
Dafür steht ein IBM Rack Server x3850 M2 zur Verfügung, mit folgender Ausstattung:
vier Xeon E7330 Quad-Core mit 2,4 GHz, 64GB DDR2 RAM, vier 500GB 2,5 Zoll SATA Festplatten von Western Digital mit 7.200 U/min und einem MR10k Raid-Controller.
Als Virtualisierungssoftware kommt \Gls{esxi} in der kostenlosen Version 6.0 mit \Gls{vsphere} 6.0 als Testversion zum Einsatz.
Mit dieser Virtualisierungslösung ist es möglich, Ressourcen explizit und ausschließlich einer \Gls{vm} zuzuordnen.
So werden die Prozessorkerne in Paaren und der Arbeitsspeicher direkt und mit exklusiver Verwendung den einzelnen \Gls{vm}s zugeordnet.
Ziel dieser unter Abbildung \ref{fig:physAufb} skizzierten Testumgebung ist es Postgres-XL mit der PostgreSQL Konfiguration des Ist Standes zu vergleichen, einen homogenen Cluster zu erzeugen und Aussagen über die Skalierbarkeit von Postgres-XL zu treffen.
Die Ausstattung des Computers zur Verwaltung der Virtualisierung wird nicht definiert, da dies keinen Einfluss auf Messungen hat.
Die \Gls{vm}s sind in Abbildung \ref{fig:VMAufb} dargestellt.
Typ I enthält eine GTM Instanz und Typ II eine GTM-Proxy, eine Coordinator und zwei DataNode Instanzen.
Dabei stehen sechs Typ II VMs zur Verfügung, wobei zur Beurteilung der Skalierbarkeit zwei bis sieben genutzt werden.
Jede \Gls{vm} besitzt als Betriebssystem Ubuntu 14.04 LTS und alle für die Installation und Ausführung des Prototypen notwendigen Pakete.
Weiterhin erhalten die Typ II \Gls{vm}s folgende Hardware Zuordnung:
zwei Prozessorkerne, sieben GB RAM und 100 GB Festplattenspeicherplatz.
Typ I erhält dagegen zwei Prozessorkerne, sieben GB RAM und 20 GB Festplattenspeicherplatz.
\begin{figure}[h!]
\centering
\input{Abbildungen/Testsystem_physischerAufbau.tex}
\caption[Aufbau der Geräte des Testsystems]{Aufbau der Geräte des Testsystems}
\label{fig:physAufb}
\end{figure}
\begin{figure}[h!]
\centering
\input{Abbildungen/Testsystem_VMs.tex}
\caption[Aufbau der VMs des Testsystems]{Aufbau der VMs des Testsystems}
\label{fig:VMAufb}
\end{figure}

Als Referenzsystem wird ein Ubuntu System mit PostgreSQL 9.3.5, PostGIS 2.1.5 und R sowie der Hardwareausstattung einer Typ II \Gls{vm} verwendet.
Mit der Übereinstimmung der Hardware Ausstattung der \Gls{vm}s ist eine Vergleichbarkeit von PostgreSQL und Postgres-XL gegeben.
Außerdem kann durch Verkleinerung und Vergrößerung des Clusters die Skalierbarkeit von Postgres-XL bewertet werden.

Die physischen Festspeicher des Testservers stehen den \Gls{vm}s nicht exklusiv zur Verfügung.
Die Anzahl an Operationen pro Zeiteinheit auf diesem Medium soll für alle \Gls{vm}s annähernd gleich sein.
Als Kompromiss aus Verteilung der Last auf alle Festspeicher, Ausfallsicherheit und Kosten, werden die Festspeicher in einem RAID 5 Verbund zusammengefasst.
So stehen 1,4 TB Festspeicher zur Verfügung.
Die \Gls{vm}s sind mit virtuellen Netzwerkkarten von 10GBit/s verbunden, wodurch die Kosten der Datenübertragung im Netzwerk vernachlässigt werden können.
Um die Vergleichbarkeit der zeitlich abhängigen Messwerte zu gewährleisten, wird ESXi als Zeitgeber für alle \Gls{vm}s eingerichtet.
Zur Überwachung der Auslastung der einzelnen \Gls{vm}s bietet VMware mit vSphere einfache Graphen für die zeitabhängige Auslastung der einzelnen Kerne, des Arbeitsspeichers und weiterer Komponenten.
Diese Graphen besitzen als zeitliche Achse einen beliebigen Bereich bis zum momentanen Zeitpunkt.
Damit sind historische Daten für einzelne \Gls{vm}s und ausgewählte Zeiträume nicht darstellbar.
Deshalb wird zur Überwachung Zabbix eingesetzt.
Zabbix ist ein freies Framework zur Überwachung von Computern und Netzwerken.
Auf einem Zabbix Server werden Daten zentral von beliebigen Zabbix Clients empfangen.
Dabei sind die Art der zu überwachenden Daten beliebig, standardmäßig wird die Systemauslastung und allgemeine Daten zum jeweiligen System an den Server gesendet.
Dazu können eigene Skripts installiert werden und Protokolle wie \Gls{snmp} oder \Gls{ipmi} zur Datenerhebung und Verwaltung genutzt werden.
Ein Zabbix Server wird zur Analyse und Verwaltung der Zabbix Clients mit einem PHP Web-Frontend versehen.
Über dieses Frontend können Clients konfiguriert, deren Status eingesehen, Diagramme zu erhobenen Daten definiert und angezeigt werden.
Weiterhin ist Zabbix ein Mehrbenutzer System und reagiert mit Funktionsaufrufen oder E-Mails auf definierte Ereignisse wie den Ausfall einzelner Clients.
%Installation im Anhang?

%Überwachung der logs?

\subsection{Funktionstests}
Im Abschnitt Prototypische Implementierung auf Seite \pageref{grundlagen-funktionstests} wurden die Funktionstests bereits als Black-Box Tests definiert und der Umfang im Kapitel \ref{subsection:testfaelle} genauer festgesetzt.
In diesem Abschnitt werden die Funktionstests für die Durchführung spezifiziert und deren Ergebnis festgehalten.
Es wird eine vollständige Erfüllung der Funktionstests erwartet, da PostgreSQL 9.2 und PostGIS 2.1.5 an sich die gesetzten Anforderungen erfüllen.
Das Fehlen von Triggerfunktionen in Postgres-XL wird durch die Funktionstests nicht aufgedeckt.
Jedoch ist dies als wesentliche Einschränkung festzuhalten und für die Auswertung heran zu ziehen.

Alle Funktionstests werden im Anhang \ref{appendix:funktionstests} in Form eines Testdokumentes\footnote{ein Testdokument mit Testfällen in tabellarischer Form, wie es in der Softwareentwicklung zum Einsatz kommt} zusätzlich dargelegt.
Darin wird der Testfall beschrieben, die Testdaten konkretisiert, das Sollergebnis vordefiniert, das schlussendliche Ergebnis dargestellt und die Akzeptanz des Tests erläutert.
Entsprechend der Reihenfolge der Testfälle im Anhang werden nachfolgend die Tests mit deren Durchführung und deren Ergebnissen präsentiert.
Die Testfälle werden durchnummeriert und mit einem vorangestellten FT für Funktionstest bezeichnet.
Dabei werden die Testfälle mit absteigender Priorität aufgelistet.
Die Priorität hängt vom geschätzten Implementationsaufwand zur Behebung des Fehlschlages des Testfalles ab.
%Nummerierung der Testfälle?

\textbf{FT01:}\\
Die Schnittstellen sind nicht explizit zu testen, da Postgres-XL und PostgreSQL wie in Abschnitt \ref{subsection:interface} demonstriert direkt Daten austauschen können.
%Schnittstellen: PostgreSQL mit dblink demonstrieren; PostGIS: Tabelle mit geometry erzeugen, füllen und Funktionen darauf anwenden; UMN: simples Mapfile für nsensorlogs erstellen

\textbf{FT02:}\\
%vorhandenes Mapfile verwenden und schauen was passiert
Für diesen Funktionstest wird der \Gls{umn} als \Gls{fcgi} Modul und einem geeigneten Mapfile verwendet.
Es wird ein Kartenausschnitt vom \Gls{umn} angefordert, welcher drei Schläge enthält.
Arbeitet Postgres-XL mit dem \Gls{umn} korrekt zusammen, liegt ein Bild mit den Schlägen in Form von  grauen Polygonen als Ergebnis vor.

\textbf{FT03:}\\
Da beide Systeme PostGIS 2.1.5 verwenden, sind die Austauschformate für geografische Daten identisch.

\textbf{FT04:}\\
Mit PostGIS kann mit der Funktion st\_{}transform direkt zwischen den Koordinatenreferenzsystemen umgerechnet werden:\\
\textit{select id, st\_{}astext(st\_{}transform(geom, 3857)) as transformed, st\_{}srid(st\_{}transform(geom, 3857)) as newsrid, st\_{}astext(st\_{}transform(st\_{}transform(geom, 3857), 4326)) as original, st\_{}srid(st\_{}transform(st\_{}transform(geom, 3857), 4326)) as srid from nutrients.samples limit 10;}\\
So werden die Punkte der Tabelle samples im Schema nutrients mit dem EPSG Code 4326 zum EPSG Code 3857 sowie wieder zurück umgerechnet.
Die Funktionsdeklaration lautet:
\textit{geometry ST\_{}Transform(geometry g1, integer srid);}\\
srid ist dabei ein EPSG Code aus der Tabelle SPATIAL\_{}REF\_{}SYS, welche 3911 Einträge im Testsystem enthält.
geometry steht dagegen für einen beliebigen räumlichen Datentyp.

\textbf{FT05:}\\
Auch in diesem Funktiontests findet die Validierung anhand von Bildern statt.
Es werden sich überlappende Polygone aus farm.fields heraus gesucht und mit Hilfe von PostGIS Funktionen verschnitten.
Dafür werden folgende Funktionen verwendet:\\
\textit{geometry ST\_{}Intersection( geometry geomA , geometry geomB );}\\
\textit{geometry ST\_{}Union(geometry g1, geometry g2);}\\
\textit{geometry ST\_{}Difference(geometry geomA, geometry geomB);}\\
\textit{geometry ST\_{}SymDifference(geometry geomA, geometry geomB);}\\
Das Ergebnis jedes Funktionsaufrufes wird gespeichert und zu einer Karte gerendert.
%Sandras WKT Polygone in eigene Tabelle, dafür mapfile erzeugen, Karte erstellen, verschneiden, Karten dazu auch erstellen
%POLYGON((-0.79904875148632581 0.11533888228299638,-0.78478002378121281 0.83115338882282985,0.39239001189060629 0.82401902497027335,0.38763376932223537 0.11533888228299638,-0.79904875148632581 0.11533888228299638))
%POLYGON((-0.76575505350772888 -0.33412604042806182,-0.67776456599286561 -0.11533888228299649,-0.56123662306777644 0.08680142687277048,-0.40665873959571941 0.33650416171224729,-0.09988109393579081 0.41260404280618301,0.29013079667063013 0.37931034482758619,0.61593341260404277 0.39833531510107012,0.71581450653983336 0.19619500594530315,0.85612366230677739 -0.37693222354340061,0.45897740784780017 -0.56718192627824016,-0.33293697978596903 -0.46492271105826399,-0.76575505350772888 -0.33412604042806182))

\textbf{FT06:}\\
Dies wird im zweiten Szenario der Lasttests im nachfolgenden Abschnitt durchgeführt.
%auf schwierigkeiten hinweisen

\textbf{FT07:}\\
%Betrieb mit kleinen Userlayern verwenden
Userlayer einer Halbjahresplanung besitzen begrenzende Rechtecke, welche im WKT Format wie folgt beschrieben sind: \textit{POLYGON((13.2547868501418 50.7878870616778,
13.2833057640198 50.7878870616778,13.2833057640198 50.7935526493687,\\
13.2547868501418 50.7935526493687,13.2547868501418 50.7878870616778))}.
Mit diesem können alle Schläge abhängig des Userlayers räumlich gefiltert werden.
So sind im Testsystem 13803 Schläge vorhanden.
Mit der Funktion \textit{boolean ST\_{}Intersects( geometry geomA , geometry geomB );} werden mit dem begrenzenden Rechteck überlappende Schläge gefiltert.
Dies ergibt mit dem oben genannten Rechteck 382 Schläge.
Mit \textit{boolean ST\_{}Disjoint( geometry A , geometry B );} erhält man dagegen räumlich disjunkte Schläge.
%Screenshots?
Dies soll als Beweis der Verwendbarkeit und Korrektheit der PostGIS Funktionen dienen.
Da die PostGIS Version des Ist-Standes mit der des Testsystems übereinstimmt, kann von voller Funktionalität  ausgegangen werden.
Davon ausgenommen sind Teile der Funktionsmenge zur Verarbeitung von Rasterdaten.
Da Postgres-XL internal als Transition Typ nicht unterstützt, ist die Funktionen zur Bildung der Vereinigung mit einem Raster nicht verfügbar\footnote{Installation von PostGIS wirft Fehler und legt die entsprechenden Funktionen nicht an.}.

%Darstellung mit UMN?

%Zusammenfassen!

\subsection{Leistungstests}
Die hier verwendeten Leistungstests wurden ebenfalls in Kapitel \ref{grundlagen-funktionstests} als spezielle Tests zur Messung der Leistungsfähigkeit und Effizienz definiert.
%Systemüberwachung
Kapitel \ref{subsection:testfaelle} beschreibt unabhängig des Testsystems die Arten der Leistungstests.
Nachfolgend wird auf den Aufbau der Tests, deren Durchführung und deren Ergebnis eingegangen.
Zusammenfassend ist das Ziel dieser Leistungstests, die spezielle Leistung gegenüber des Ist-Standes und die Skalierbarkeit von Postgres-XL zu ermitteln. %Skalierbarkeit raus lassen?
%Skalierbarkeit(T(1)/T(p))/Effizienz(S(p)/p)
Es wird von einer höheren Leistung, abhängig der Anzahl der verwendeten Knoten, bei der Aggregation und der Verarbeitung im Gegensatz zum Ist-Stand ausgegangen.
Zwar sind bei Postgres-XL lokale Anfragen mit mehr administrativen Aufwand verbunden und werden somit langsamer gegenüber einer PostgreSQL Instanz bearbeitet, jedoch stehen mehrere Zugriffspunkte auf exklusiven Hardwaresystemen zur Verfügung.
Der Faktor der Beschleunigung der Abarbeitung einer festgelegten Menge von gleichzeitigen Abfragen abhängig der Anzahl der Knoten ist zu ermitteln.

%gleichmäßige Beeinflussung durch Zabbix nennen
Analog des Testaufbaus der Bachelor Arbeit des Autors\footnote{\cite{ba:kurt}} wird zur Generierung der Last das freie Java Programm JMeter verwendet, welches mehrere vorbereitete Anfragen parallel und verschränkt erzeugt sowie eine Auswertung der Laufzeiten zur Verfügung stellt.
Ein Testlauf wir dabei per Kommandozeile gestartet und die Ergebnisse in einer .csv Datei festgehalten.
Diese Datei wird anschließend mit der grafischen Oberfläche von JMeter geöffnet und die Daten in grafischer Form ausgewertet.
JMeter wird von einem externen Computer ausgeführt.
Dieser ist mit 1GBit/s an das Testsystem angebunden und besitzt die folgende Ausstattung:
16GB DDR3 RAM, 256GB mSata3 SSD und eine Intel i5-3320M Dual-Core CPU mit 2,6GHz und Hyperthreading.

Um ein statistisches Mittel zu erreichen und Nebeneffekte des Caching der Datenbank und des Betriebssystems zu reduzieren, wird ein Test elf mal ausgeführt.
Es werden die zehn letzten Tests gemessen, der höchste und der niedrigste Wert ausgeschlossen und die letztendlichen acht Werte gemittelt.
Außerdem wird Postgres-XL vor jeder Testreihe neu gestartet.
Dieses Vorgehen orientiert sich an der Masterarbeit von Baas Kapitel 6.1 Objective measurements\footnote{\cite[S.51]{ma:neo4j}}.
Die Graphen der Auslastung der Knoten liegen als Bilder vor.
Deshalb wird ein repräsentatives ausgewählt und zum Vergleich heran gezogen.

Es besteht die Möglichkeit die theoretische Leistung anhand des Kostenmaßes zu bestimmen.
Nach \cite[S.300 f.]{book:kudrass} setzen sich die Kosten für die Verarbeitung einer Anfrage aus folgendem zusammen:
\begin{description}
\item[Rechenzeit] Dazu zählt die Zeit des Syntaxprüfers, des Ausführungsplaners, der Kombinierung und der Sortierung.
\item[Ein- und Ausgabe] Besteht aus der Anzahl der Aufrufe an das Speichersystem und der Protokollierung mit internem Speichermanagement.
\item[Datenübertragung] Meint die Übertragung von Befehlen und Daten zwischen Komponenten.
\end{description}
Weiterhin sind Einflussfaktoren das  logische Datenbank Design, die Anwendung, die Abfrage, der Ausführungsplan, die Datenmenge der Abfrage, das physisches Datenbank Design, die Größe der Datenbank, das \Gls{dbms}, die Systemlast, das Netzwerk, die  Parallelität und das Betriebssystem.
Eine Berechnung des einheitenlosen Kostenmaßes fällt auf Grund der Komplexität des Anwendungsfalles und der Menge der Einflussfaktoren aufwendig aus.
Deshalb wird die Verarbeitungsleistung empirisch mit Tests festgestellt.
%In Grundlagen-Tests vrschieben?

Postgres-XL arbeitet mit verteilten Daten.
Diese werden entweder auf jeden Knoten repliziert oder zwischen den Knoten aufgeteilt.
Abhängig von der Verteilung der Daten und deren Aufrufen ergeben sich unterschiedliche Ergebnisse der Leistungsmessung.
Entscheidend für die Laufzeit einer Anfrage an die Datenbank ist die Aufteilung dieser durch den Query Planer.
Die erste Query Planer Instanz ist jene des angesprochenen Coordinators.
Diese erstellt Unterabfragen entsprechend der Verteilung der Daten auf den DataNodes.
Diese Unterabfragen werden lokal vom entsprechendem DataNode verarbeitet und das Ergebnis an den Coordinator zurück gesendet.
Diese Zwischenergebnisse werden schlussendlich vom Coordinator zusammengefasst.
Somit sind die Daten entsprechend ihrer Verknüpfung hinsichtlich des Datenbankschemas und des Anwendungsfalles für ein geeignetes Zerlegen von Aufgaben durch den Query Planer zu verteilen.
Geeignet meint hier das die Unterabfragen bereits wesentlich die Daten filtern, damit der Coordinator einzig die Untermengen zu einer Menge zusammenfassen und nicht grobe große Datenmengen aggregiert und diese selbst verknüpfen sowie filtern muss.
Auf das Schema angewendet bedeutet dies:\\
Die Tabellen fields und farms des Schemas farm werden per Replikation auf alle Knoten verteilt, da diese häufig zur nummerischen und räumlichen Filterung verwendet werden und somit jedem DataNode zur Filterung zur Verfügung stehen.
Die Tabelle nsensorlogs im Schema n und die Tabelle samples im Schema nutrients werden anhand des Attributes fileid mit modulo auf die DataNodes verteilt, da dieses Attribut als primäres Filterargument verwendet wird.
Das Attribut fileid ist für eine modulo Verteilung geeignet, da Gruppen von files mit aufsteigender id zu einem Betrieb gehören und bei modulo Verteilung die Wahrscheinlichkeit erhöht wird, dass ein DataNode die files eines Betriebes vorhält.\footnote{Bezogen auf eine betriebsübergreifende Verarbeitung.}\\
Diese Verteilung sollte sich positiv auf die Ergebnisse der Leistungstests auswirken.
Es wurden einzig Tabellen berücksichtigt, welche in den Tests verwendet werden.
Für den produktiven Einsatz bei der Agri~Con entsprechend des Anwendungsfalles sind weitere Änderung in der Verteilung der Daten durchzuführen.
%Verteilung in Ausblick aufnehmen
%Nach Kudraß
%Erwartung der Treffer (Selektivität) und Histogramme (erzeugt mit analyze) sollen einbezogen werden S.261f.
%S.401 horizontale Fragmentierung wird mit create table distribute by durchgeführt (Datenlokalisierung S.407)

Entscheidend für die Leistungsfähigkeit des \Gls{dbms} ist ebenfalls die Konfiguration des Query Planers.
Dazu zählt die Vergabe von Kostenwerten an Funktionen und das Setzen von Konfigurationen wie den Kostenfaktoren und der Algorithmennutzung in den postgresql.conf Dateien.
Diese Einstellungen werden im Rahmen dieser Arbeit auf Standardwerten belassen, da eine solche Konfiguration sehr stark von den Anfragen und somit von Anwendungsfall abhängt.
Da das Vergleichssystem mit PostgreSQL die selbe Konfiguration besitzt ist eine relative Vergleichbarkeit gewährleistet.
Für einen produktiven Einsatz ist die Berücksichtigung dessen zu empfehlen.
So besteht auch die Möglichkeit Coordinator mit unterschiedlichen Konfigurationen auszustatten, um mehrere Aspekte des Anwendungsfalles abzudecken.
%Im Ausblick erneut darauf eingehen
%Aggregation ohne joins und Unterabfragen -> gewählte Verteilung der Daten und QueryPlaner Bestimmungen sind sehr speziell - für eigene Thesis - für diesen Fall keine Berücksichtigung dieser Feinheiten

%Verteilung der Anfragen an alle Coordinator
% -> definitive Steigerung der Leistungsfähigkeit  (mehr beantwortete Anfragen pro Sekunde)

\subsubsection{Erster Lasttest}
Der erste Lasttest misst die Laufzeit der Aggregation von Punktdaten aus der Tabelle nsensorlogs des Schemas n.
Die Abfrage und Messung erfolgt mit dem SQL Statement \textit{Select * From n.nsensorlogs Where fileid=\%{};} sowie \textit{Explain Verbose Select * From n.nsensorlogs Where fileid=\%{};}.
Die erste Query liefert die Daten sowie Laufzeit\footnote{Sofern in PostgreSQL die Zeiterfassung mit \textbackslash{}timing eingeschaltet wurde.} und die zweite die Aufteilung des SQL Statements an die Knoten des Clusters.
Der Aufruf der ersten Query erfolgt parallel an alle Coordinator und wird für den Lasttest verwendet.
Diese zweite Query wird ein mal pro Coordinator abgerufen, um die Verteilung der Daten zu validieren.
\%{} steht dafür für einen Integer Wert und ist einer aus files.soilsamplefiles.id.
Es werden die sechs Werte mit der größten Menge an Einträgen, aufgelistet in Tabelle \ref{tbl:entrysnnsensorlogs}, in n.nsensorlogs verwendet.
Die fileids wurden gleichzeitig so gewählt, dass jeder Datensatz einer fileid auf einem anderen Knoten vorhanden ist.
Somit werden alle Knoten gleichmäßig angesprochen.
\begin{table}[h!]
\centering
\small
\begin{tabular}{c|c}
\textbf{fileid} & \textbf{Anzahl Einträge} \\ \hline
10591 & 37.926 \\ \hline	%dn 5 node3
9396 & 36.873 \\ \hline		%dn 1 node1
34791 & 33.913 \\ \hline 	%dn 12 node6
9394 & 33.391 \\ \hline 	%dn 8 node4
10595 & 28.342 \\ \hline	%dn 9 node5
44982 & 20.494 \\ 			%dn 4 node2
\end{tabular}
\caption{Anzahl der Einträge in n.nsensorlogs nach fileid}
\label{tbl:entrysnnsensorlogs}
\end{table}
Zusätzlich erfolgt die Aggregation in einem gesonderten Test entsprechend des Anwendungsfalles mit dem \Gls{umn}, mit der Darstellung in Kartenform als Ergebnis.
Dafür wird der \Gls{umn} mit einem Mapfile als \Gls{fcgi} Modul verwendet, siehe Anhang \ref{appendix:mapfileaggregate}.
Das Mapfile stellt Kartenausschnitte der Punktdaten dar und die Karte wird farbig anhand der Metadaten erzeugt.
%Aggregation
%Query vorbereiten   select * from n.nsensorlogs where farmid=1038
%Laufzeitmessung testen   explain analyze
%Auslastung messen/testen    mit Zabbix
%mehrere Durchgänge
%gegenüber stellen



%\begin{figure}[h!]
%\centering
%\begin{subfigure}{.5\textwidth}
%  \centering
%  \includegraphics[width=.4\linewidth]{Abbildungen/}
%  \caption{}
%  \label{fig:sub1}
%\end{subfigure}%
%\begin{subfigure}{.5\textwidth}
%  \centering
%  \includegraphics[width=.4\linewidth]{Abbildungen/}
%  \caption{}
%  \label{fig:sub2}
%\end{subfigure}
%\caption{}
%\label{fig:}
%\end{figure}

%\begin{figure}[!ht]
%  \begin{minipage}{\textwidth}
%    \centering
%    \includegraphics[width=.4\textwidth]{figure1}\quad
%    \includegraphics[width=.4\textwidth]{figure2}\\
%    \includegraphics[width=.4\textwidth]{figure3}\quad
%    \includegraphics[width=.4\textwidth]{figure4}
%    \subcaption{First subfigure.}
%    \label{fig:sub1}
%  \end{minipage}\\[1em]
%  \begin{minipage}{\textwidth}
%    \centering
%    \includegraphics[width=.4\textwidth]{figure5}\quad
%    \includegraphics[width=.4\textwidth]{figure6}\\
%    \includegraphics[width=.4\textwidth]{figure7}\quad
%    \includegraphics[width=.4\textwidth]{figure8}
%    \subcaption{Second subfigure.}
%    \label{fig:sub2}
%  \end{minipage}
%\end{figure}

%Bilder unteinander setzen: Auslastung, Laufzeiten
%diese auswerten

%exlain aller 6 fileids auf einem coodinator ausführen - bei anderen ist es analog
% -< eventuell fileids ändern, um gleichverteilung zu erreichen?
%dies kurz darlegen

%UMN aktivieren und JMeter konfigurieren -> Beispielhafte BBOX raussuchen
% -> Userlayer bbox oder kleinen client bauen

\subsubsection{Zweiter Lasttest}
Der Lasttest zum messen der Verarbeitungsleistung ruft die SQL Funktion\\
\textit{nutrients.contouringcorrectedatop(integer)} auf.
Diese führt den speziellen Kriging Algorithmus anhand der übergebenen fileid mit den Werten in nutrients.samples durch.
Es werden fileids aus der Tabelle \ref{tbl:entrysnsamples} verwendet.
\begin{table}[h!]
\centering
\small
\begin{tabular}{c|c}
\textbf{fileid} & \textbf{Anzahl Einträge} \\ \hline
3904 & 260 \\ \hline
742 & 201 \\ \hline
4204 & 197 \\ \hline
4186 & 160 \\ \hline
5796 & 143 \\ \hline
5915 & 110 \\
\end{tabular}
\caption{Anzahl der Einträge in nutrients.samples nach fileid}
\label{tbl:entrysnsamples}
\end{table}
Neben der Laufzeit ist gesondert die Auslastung der einzelnen Knoten zu beobachten und zu bewerten.
Zu Beginn dieser Untersuchung steht nicht fest, in wie weit die DataNodes mit in die Berechnungen der Coordinator mit einbezogen werden.
%Nur Coordinator schein zu berechnen - dies ist mit auslastung EINES Coordinator zu beweisen
Eine automatisierte Verteilung der Berechnungen ist für einen höheren Durchsatz wünschenswert.
Auch hierbei werden die Anfragen gleichmäßig auf die Coordinator verteilt.
%mehrere Aufrufe gleichzeitig - mit scala?

Es zeigte sich, dass mit Postgres-XL zwar Daten per SQL \textit{Insert into} gespeichert werden können, es jedoch bei einer Speicherung innerhalb einer SQL Funktion zu Fehlern kommt.
In der Fehlermeldung wird auf unbekannte Parameter verwiesen, obwohl alle Daten in Parametern korrekt sind.
Aus diesem Grund wurden die Funktionen der Berechnung angepasst, sodass zwar alle Berechnungen durchgeführt werden, die Ergebnisse aber nicht verfügbar sind.
Weiterhin zeigte sich, dass Funktionen welche die Erweiterung plr für die Nutzung der Sprache R verwenden, zufällige Fehler werfen.
Die Wahrscheinlichkeit des Auftretens des Fehlers konnte durch neu laden der verwendeten R Bibliotheken bei jedem Funktionsaufruf veringert werden.
So wird \textit{nutrients.contouringcorrectedatop(integer)} ohne Nebenwirkungen ausgeführt und endet zufällig mit oder ohne Fehler.
Dieser Lasttest wird trotzdem durchgeführt, wobei die Anzahl der Fehlschläge gesondert festgehalten wird.

%Nur einen Coordinator ansprechen und Auslastung beobachten
% Auslastungen als Bilder in Anhang und darauf verweisen
% nur coodinator scheint augelastet zu werden - bewerten

%Bilder unteinander setzen: Auslastung, Laufzeiten
% diese auswerten
% auf Fehleranteil eingehen

%mit SQL Bordmitteln - pg_bench eventuell zusätzlich um ein paar Aussagen zum cluster overhead zu treffen

%PostgreSQL System nicht vergessen!