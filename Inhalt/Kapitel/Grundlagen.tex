\chapter{Grundlagen}

\section{Datenbank}

\subsection{Begriffsdefinitionen}

\subsubsection{ACID}
Die bekanntesten Vertreter von relationalen Datenbanksystemen wie Oracle, MySQL und PostgreSQL arbeiten transaktional nach \Gls{acid}.
\Gls{acid} kann nach \cite{book:kudrass} S. 262 wie folgt definiert werden:
\begin{description}
\item[Atomarität] \hfill \\
Transaktionen sind atomar, wodurch ein Abbruch einer Transaktion deren enthaltenen Operationen rückgängig macht.
\item[Konsistenz] \hfill \\
Das Ende oder der Abbruch einer Transaktion geht immer mit Nachbedingung aller Intergritätsbedingungen einher.
\item[Isolation] \hfill \\
Transaktionen verschiedener Benutzer beeinflussen sich nicht gegenseitig.
\item[Dauerhaftigkeit] \hfill \\
Jede Änderung einer Transaktion ist nach Ende dieser auf die Festplatte geschrieben und nicht mehr im Puffer vorhanden.
\end{description}
Die Definition dieses anerkannten Begriffes ist für Kapitel 2.3 notwendig.

\subsubsection{MVCC}
In grundlegenden relationalen Systemen werden Transaktionen verzögert oder sogar gesperrt, um Konsistenz und Isolation zu gewährleisten.
\Gls{mvcc} erhöht die Effizienz des  blockierenden Verhaltens.
Dabei werden von jedem Objekt mehrere Versionen verwaltet.
Neue Versionen entstehen durch Änderungen einer anderen.
Eine Transaktion verwendet die zu Transaktionsbeginn aktuelle Version.
Dadurch werden die allgemeinen Sperrverfahren (siehe \cite{book:kudrass} S. 266 ff.) verbessert, indem lesende Transaktionen sich nicht gegenseitig blockieren und schreibende- gegen lesende Transaktionen nicht mehr synchronisiert werden müssen. (vgl. \cite{book:kudrass} S. 270)

\subsubsection{BASE}
\Gls{base} ist ein optimistischer und sperrenfreier Ansatz mit fließender Konsistenz.
\cite{book:nosql-einfuehrung}

\subsubsection{CAP}
\Gls{cap}

\subsubsection{Partition Tolerance}

\subsubsection{Eventual-Consistency}

\subsubsection{Consistent-Hashing}


%weitere Begriffsdefinitionen

\subsection{Indexstrukturen}

Indexstrukturen oder allgemein Zugriffsstrukturen dienen dem effizienten Zugriff auf Dateneinträge.
Ein Index ist nach \cite{book:kudrass} S. 284 wie folgt definiert:
\begin{quote}
Ein Index ist ein Verzeichnis von Dateneinträgen der Form (k, k*), das den effizienten Zugriff auf allen Einträgen mit einem Suchschlüsselwert k erlaubt. Dabei bezeichnet k den Wert eines Suchschlüssels (auch Zugriffsattribut) und k* den Verweis auf den Datensatz in der Datei, der k als Wert des Suchschlüssels enthält.
\end{quote}
Zugriffsstrukturen haben je nach Art und Umfang der Daten sowie entsprechend den Anforderungen an das \Gls{dbs} unterschiedliche Strukturen.
In der einfachsten Struktur unterscheidet man nach Indexen die direkt die Daten beinhalten, auf die Daten zeigen oder eine Menge von Adressen beinhalten. (siehe \cite{book:kudrass} S. 284)

Im folgenden werden spezielle Indexstrukturen vorgestellt, da dieses Wissen zur Bewertung von \Gls{dbs} herangezogen werden müssen.

\subsubsection{B-Baum}

\begin{quote}
Der B-Baum ist ein dynamisch balancierter Indexbaum, bei dem jeder Indexeintrag auf eine Seite der Hauptdatei zeigt.\footnote{\cite{book:kudrass} S. 288}
\end{quote}
Der Baum besitzt die Höhe h und die Ordnung m sowie die folgenden Eigenschaften:
\begin{quote}
1. Jeder Weg von der Wurzel zum Blatt hat die Länge h (balanciert)\\
2. Jeder Knoten enthält mindestens m Elemente (außer der Wurzel) und  höchstens 2m Elemente (mindestens halbvolle Belegung)\\
3. Jeder Knoten ist entweder eine Blattseite oder hat höchstens 2m + 1 Kinder (maximale Belegung)\footnote{ebenda}
\end{quote}
Diese Struktur garantiert eine Belegung von 50\%.
Weiterhin beschreibt h die Anzahl der Seitenzugriffe als relevantes Maß für die Zugriffskosten und Datensätze n bedingen den Zugriff in maximal logm(n) Seitenzugriffen. (vgl. \cite{book:kudrass} S. 288)

Eine Spezialisierung stellt der B+-Baum dar.
Hierbei befinden sich die Dateneinträge ausschließlich in den Blattknoten.
Die Blattknoten sind unidirektional verkettet.
%Ordnung ist hier (m -> Mindestbelegung für Indexseiten, m* -> Mindestbelegung der Blattseiten) m>m*

\subsubsection{LSM-Baum}
Log structured merge tree

\subsubsection{R-Baum}
R-Bäume sind balancierte Bäume und \glqq organisieren k-dimensionale Rechtecke mithilfe überlappender Blockregionen\grqq \ (\cite{book:kudrass} S. 523)
Diese Struktur wird folglich zur räumlichen Datenhaltung eingesetzt, da die Indexierung anhand räumlicher Informationen der Daten erfolgt.
Ein Verzeichnisknoten besteht aus einem Tupel (ref, mur).
ref steht für den Verweis auf den direkten Nachfahren und mur für das minimal umgebende Rechteck der Kindknoten.
Datenknoten enthalten dagegen nur mur als eigentliches Geoobjekt. (vgl. \cite{book:kudrass} S. 523 ff.)

\subsubsection{Geohash}

\subsection{Mehrrechner-Datenbanksystem}

\begin{quote}
Bei einem Mehrrechner-Datenbanksystem (MDBS) werden die Datenbankverwaltungsfunktionen auf mehreren Prozessoren bzw. Rechnern ausgeführt.\footnote{\cite{book:kudrass} S. 394}
\end{quote}
Kudraß ergänzt dies durch folgende Unterscheidungen:
\begin{description}
\item[shared everything] \Gls{dbms} befindet sich auf eng gekoppelter Multiprozessor-Umgebung.
\item[shared nothing] Die Verarbeitung erfolgt durch mehrere Rechner mit jeweils einem \Gls{dbms}, dabei ist der Externspeicher unter den beteiligten Rechnern partitioniert.
\item[shared disk] Hierbei handelt es sich um mehrere lokal angeordnete, lose oder nah gekoppelte Rechner mit je einem \Gls{dbms} und einer gemeinsamen Speicherzuordnung. Lokal verteilte Systeme werden als parallele Datenbanksysteme bezeichnet.
\end{description}

\subsection{Verteiltes Datenbanksystem}

\begin{quote}
Verteilte Datenbanksysteme (VDBS) sind geografisch verteilte Shared-Nothing Systeme mit homogenen lokalen DBMS, die gemeinsam ein globales konzeptionelles DB-Schema unterstützen.
Förderierte Datenbanksysteme (FDBS) sind ebenfalls geografisch verteilte Sgated nothing systeme, wobei die beteiligten lokalen DBMS eine höhere Autonomie aufweisen, d.h. dass jeweils eine eigene lokale Datenbank mit lokalem DB-schema vorliegt.\footnote{\cite{book:kudrass} S. 398}
\end{quote}

\subsection{Replikationsverfahren}

\subsubsection{Synchron}

\subsubsection{Asynchron}

\subsubsection{Kaskadiert}

\newpage

\section{geografische Datenverarbeitung}

\subsection{Bezugssysteme}

\subsection{Datenformate}


\begin{quote}
Geoobjekte sind räumliche Elemente, die zusätzlich zu Sachinformationen geometrische und topologische Eigenschaften besitzen und zeitlichen Veränderungen unterliegen können. Kennzeichnend für Geoobjekte sind somit Geometrie, Topologie, Thematik und Dynamik.\footnote{\cite{book:gi-theopluspraxis3} S. 133}
\end{quote}
De Lange definiert räumliche Objekte bzw. Geoobjekte ausreichend.
Ein Geoobjekt enthält als Geometrie eine oder mehrere zwei- oder dreidimensionale Koordinaten, was die Lage, den Umfang und die Ausdehnung beschreibt.
Zur Topologie zählt de Lange Umgebungen, Nachbarschaften, Teilmengen und Überlagerungen.
Weiterhin werden Geoobjekte mit Sachinformationen gespeichert und je nach Anwendungsfall versioniert.[vgl. \cite{book:gi-theopluspraxis3} S. 133]


\subsubsection{einfache Geoobjekte}

Ein Punkt besteht aus einer zwei- oder dreidimensionalen Koordinate und beliebigen Sach-, Topologie- und Dynamikinformationen.
Mehrere Punkte bilden Linien.
Bildet eine Linie eine geschlossene Fläche, handelt es sich um ein Polygon.

\subsubsection{Vektorenmodell}

Es besteht die Möglichkeit eine Menge von Punkten als Vektoren aufzufassen und daraus topologische Objekte entstehen zu lassen.
Um damit geografisch zu modellieren, ist eine Diskretisierung d.h. eine Zuordnung der Vektoren notwendig. 

\subsubsection{Rastermodell}

Ein Raster löst einen rechteckigen Bereich mit in einem Koordinatensystem gleichmäßig angeordneten quadratischen Bildelementen bzw. Pixeln fester Größe auf.
Geodaten werden ergo mit einer indizierten Matrix abgebildet.
Ein dreidimensionales Raster heißt Voxel.
\begin{quote}
Ein Punkt wird näherungsweise durch ein einzelnes Pixel dargestellt. Ein Linienzug wird durch entsprechende Anordnungen zusammenhängender Pixel angenähert erfasst. Linienzüge können dann z.B. durch Folgen von Indexpaaren (Zeile, Spalte) der zugehörigen Pixel beschrieben werden. Eine Fläche ist ebenfalls durch zusammenhängende Pixel darstellbar. Somit sind keine weiteren Zusatzinformationen zur Modellierung von Flächen wie im Vektormodell notwendig [...].\footnote{\cite{book:gi-theopluspraxis3} S. 136}
\end{quote}


\subsubsection{Shapefile}

\subsection{GIS}

\subsection{PostGIS}

\subsection{GeoTools}



\section{NoSQL}

\subsection{Definition}

NoSQL steht für eine Bewegung der letzten 6 Jahre, in welcher die Abkehr von klassischen relationalen Systemen gefordert oder zumindest ein Umdenken bestehender Strukturen, Vorgehen und Grundsätze angestrebt wird.
Dies wird durch andere Abfragesprachen, nicht relationale Datenbanksysteme oder Neudefinitionen von Begriffen wie der Konsistenz zum Ausdruck gebracht.
Der Ursprung wird in der Literatur verschieden hergeleitet, jedoch wird immer zu den ersten Vertretern der NoSQL Bewegung Systeme mit einer anderen Abfragesprache und einfache Schlüssel-Hash Datenbanken gezählt.
Auf einer Messe zu aktuellen Trends im Datenbankbereich wurde der Begriff NoSQL zuerst öffentlich für Lösungen dieser Bewegung verwendet [vgl. \cite{website:originnosql}] und ist seitdem ein Sammelbegriff für eine hohe Anzahl an Systemen.

\subsubsection{NoSQL GIS}

Ein \Gls{gis} ist wie folgt definiert:
\begin{quote}
Ein System,  das  auf einen Datenbestand zurückgreift und Auswertungen dieser Daten zulässt,  so dass Informationen abgeleitet und wiedergegeben werden können,  kann  allgemein  als  ein  Informationssystem  bezeichnet  werden. [...]

Im Mittelpunkt  der  Geoinformatik  stehen  mit den  Geoinformationssystemen raumbezogene Informationssysteme, die im Gegensatz zu den übrigen Informationssystemen Geoobjekte  der realen Welt modellieren und diese in ein digitales Informationssystem abbilden [...]. Die Gegenstände eines Geoinformationssystems  besitzen  wie  auch  bei  allen  anderen  Informationssystemen  eine 
Thematik (und Dynamik). Das Besondere bei Geoinformationssystemen ist, dass Geoobjekte darüber hinaus Geometrie und Topologie als implizite und untrennbare Bestandteile aufweisen!  Die Verarbeitung derartiger raumbezogener Informationen erfordert spezielle Werkzeuge bzw. Funktionen, die von den übrigen Informationssystemen nicht bereitgestellt werden [...].\footnote{\cite{book:gi-theopluspraxis3} S. 337}
\end{quote}

In Bezug auf NoSQL kann \Gls{gis} ebenso definiert werden, jedoch muss das zugrunde liegende System nicht relational sein.
Im Rahmen dieser Arbeit ist mit \Gls{gis} ein System oder die Teilsysteme zur räumlichen Datenhaltung, Datenverarbeitung und Bereitstellung gemeint.

\subsection{Kategorisierung}
Edlich unterscheidet, wie andere Autoren, NoSQL Datenbanken nach vier Kategorien.
Jedoch kann eine eindeutige Zuteilung nicht für jedes System erfolgen, da Prinzipien verschiedener Kategorien auf eines zutreffen können.
Unter \url{http://nosql-database.org/} ist eine persönliche Übersicht der NoSQL Datenbanken von Herrn Edlich dargestellt.


\subsubsection{Key Value Datenbank}



\subsubsection{Dokumentenbasierende Datenbank}

\subsubsection{Spaltenorientierte Datenbank}

\subsubsection{Graphendatanbank Datenbank}

Der bekannteste Vertreter der graphenbasierten Datenbanken ist Neo4J.
Alle Daten und deren Beziehungen werden in Form von Graphen persistiert.
Ein Graph besteht dabei aus Knoten und gerichteten Kanten.
Somit lassen sich direkt Beziehungen zwischen den Daten definieren.



\subsection{Hadoop}
% http://blog.samibadawi.com/2012/03/hive-pig-scalding-scoobi-scrunch-and.html

Hadoop ist ein unter der Apache Lizenz 2.0 stehendes Java-Framework zur Datenhaltung und Verarbeitung von großen Datenmengen auf mehrerern Computern.
Es basiert auf MapReduce und dem Dateisystem HDFS.

\Gls{hdfs} ist ein verteiltes Dateisystem, welches keine besonderen Anforderungen an die Hardware stellt und für die Verwendung von mehreren hundert bis tausend Computern\footnote{die in einem verteilten System teilnehmenden Computer heißen Knoten} ausgelegt ist.
Es besitzt eine hohe Fehlertoleranz und ist für den Einsatz auf kostengünstiger Hardware ausgelegt.
Hoher Datendurchsatz und die Verwendung großer Dateien\footnote{eine Datei kann mehrere Gigabyte bis mehrere Terrabyte groß sein und wird in Blöcke gleicher Länge aufgeteilt} sind wesentliche Merkmale.[vgl. \cite{paper:hadoop} S. 3]
Die Datei-Blöcke werden redundant auf die Knoten verteilt und sind mit Hilfe des Name-Node abrufbar.[vgl. \cite{ba:dan} S. 7]

Die verteilte Verarbeitung übernimmt MapReduce.
Entsprechend dem Namen entspringt der Name MapReduce aus der funktionalen Programmierung, in welcher die Funktionen \glqq map\grqq \ und \glqq reduce\grqq \ zum Einsatz kommen.
So werden hier die Daten mit einer map-Funktion verändert und mit reduce-Funktion aggregiert.
Ein Master weist die Daten und Funktionen den Slaves\footnote{In diesem Zusammenhang auch Worker genannt} zu.
Die Slaves führen die Funktionen mit den ihnen zugewiesenen Daten aus und speichern ihre Ergebnisse auf deren Festplatte ab.
MapReduce wurde von Google definiert.
Auch hier werden keine besonderen Anforderungen an die Hardware gestellt.[vgl. \cite{paper:mapreduce} S. 3]


Hadoop besitzt eine Master-Slave Architektur, wobei der Name-Node\footnote{damit ist der Master-Knoten gemeint, auch Jobtracker genannt} ankommende Anfragen bearbeitet und die Slave-Knoten organisiert.
Hadoop ist per API verwendbar und bietet sich somit zur Stapelverarbeitung an. %Todo: belegen
Es wird meist nur als Grundgerüst verwendet und mit Datenbanken wie HBase, MongoDB oder PostgreSQL sowie mit Frameworks für die Nutzung wie Hive, Pig, Spark oder Scalding erweitert.





\subsection{Accumulo}
\url{https://en.wikipedia.org/wiki/Apache_Accumulo}

\subsection{MongoDB}

\subsection{CouchDB}

\subsection{Neo4J}

\newpage

\subsection{Rasdaman}

\url{http://live.osgeo.org/de/overview/rasdaman_overview.html} :\\
- Array-Datenbanksystem
- PostgreSQL Aufsatz
- Multi-Dimensionalität
- eigene Anfragesprache
- skalierend
- unterstützt WCS Core und WCPS
- Implementierte Standards: OGC WMS 1.3, WCS 2.0, WCS-T 1.4, WCPS 1.0, WPS 1.0
- Lizenz: Clients und APIs: GNU Lesser General Public License (LGPL) version 3; Server-Engine: GNU General Public License (GPL) version 3
- Unterstützte Plattformen: Linux, MacOS, Solaris
- APIs: rasql, C++, Java


\url{http://www.rasdaman.org/} :\\
- open-source
- "extends standard relational database systems with the ability to store and retrieve multi-dimensional raster data"


\url{http://www.rasdaman.de/} :\\
- "erlaubt die Ablage von unbeschränkt grossen multi-dimensionalen Arrays ("Rasterdaten") in einer konventionellen Datenbank"


\subsection{Spacebase}

\url{http://docs.paralleluniverse.co/spacebase/} :\\
- serverseitig
- in-memory
- spatial data store
- ausgelegt für viele rechner und hohen Durchsatz (real-time)
- 2D und 3D Objekte mit 3D bbox
- load balancing enthalten
- spatial querys möglich
- benötigt JVM
- API für Java, Ruby, Python, Node.js, C++, Erlang
- API stellt nur elementare spatial querys zur verfügung: intersect oder contains
- eigene spatial querys können definiert werden

\subsection{Geomesa}

- Ingest = Import über Kommandozeile (geomesa-tools)
- Ingest von shp, csv und tsv Dateien
- Anderer Dateiimport mit GeoTools
- Verarbeitung nur über externe Tools (Spark, geotools)
- Export: csv, tsv, shp, geojson, gml

\url{http://www.eclipse.org/community/eclipse_newsletter/2014/march/article3.php} :\\
- open-source
- build on Accumulo and Hadoop
- Supporting the GeoTools API
- GeoServer Plugin
- geohash for indexing


\url{https://www.locationtech.org/proposals/geomesa} :\\
- outperforming postgis with geoserver


\url{http://de.slideshare.net/CCRinc/location-techdc-talk2-28465214}
- Verwendung fraktaler Kurven
- mit Spark und Scalding wesentlich schneller als PostGIS


\url{https://docs.google.com/presentation/d/1NO0ppk8MfDs8Q-QcUidZCSZK7YYwd9RjJoHV1V4Yq_w/edit?pli=1#slide=id.p} :\\
- 

%storm vs spark: http://xinhstechblog.blogspot.de/2014/06/storm-vs-spark-streaming-side-by-side.html https://stackoverflow.com/questions/24119897/apache-spark-vs-apache-storm http://www.zdatainc.com/2014/09/apache-storm-apache-spark/


\url{https://github.com/locationtech/geomesa}:\\
- Apache License Version 2.0


\subsection{ESRI GIS Tools for Hadoop}
- 4 elements\\
- Esri Geometry API for Java: "This is a generic library that includes geometry objects, spatial operations, and spatial indexing, it can be used to spatially enable Hadoop. By deploying the Esri geometry API library (as a jar) within Hadoop, developers are able to build Map/Reduce applications that are spatially enabled, by leveraging the Esri Geometry API along with the other Hadoop APIs in their application."\cite{website:esri-hadoop2}\\
- Spatial Framework for Hadoop: "This library includes the user defined objects that extend Hive with the capabilities of the Esri Geometry API. By enabling this library in Hive, users are able to construct queries that are very SQL like using HQL. In this case, users don’t have to write a Map/Reduce application, they can interact with Hive, write their SQL like queries and get answers directly from Hadoop. Queries in this case can include spatial operations and values."\cite{website:esri-hadoop2}\\
- Geoprocessing Tools for Hadoop: "These tools are specifically used in ArcGIS. Through the tools, users can connect to Hadoop from ArcGIS. Connecting to Hadoop from ArcGIS is really useful to the toolkit users, since they can import their analysis result in ArcGIS for Visualization. They can also do more complex and sophisticated analysis now that they narrowed down their data to a specific subset. Additionally, users can leverage the ArcGIS platform capabilities to publish their maps to web and mobile apps, and can integrate it with BI reports."\cite{website:esri-hadoop2}\\
- GIS Tools for Hadoop: "This project is intended as a place to include multiple samples that leverage the toolkit. The samples can leverage the low level libraries, or the Geoprocessing tools. A couple of samples are available to help you test the deployment of the spatial libraries with Hadoop and Hive, and make sure everything runs with no issues before you start leveraging the setup from your HQL queries, or from the GP tools. To check your deployment, for Hive and GP tools usage, the sample point-in-polygon-aggregation-hive can be utilized. The sample leverages the data and lib directories on the same path."\cite{website:esri-hadoop2} (Benötigt ArcGIS)\\
- Apache License, Version 2.0

\section{Leistungstests}

- siehe BA
- in Absprache mit Prof. Riechert