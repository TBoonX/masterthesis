Hadoop GIS: A High Performance Spatial Data Warehousing System over MapReduce

Indroduction ebschreibt Anforderungen an Umgebung: Big Data, high computation complexity
there are two major problems to handle for spatial partitioning: spatial data skew problem and boundary object problem.
spatial query algorithm created
eigene query engine RESQUE: verwendet map/reduce von hadoop, hive anbindung, diverse staial query arten möglich (speziell für rasterdaten mit tiles)
---------------------------------------------------------------------

Seminararbeit Dan: Spark und Shark

Kapitel 2:
Map-Reduce bei bestimmten Algorithmen langsam, da Zwischenergebnisse auf der HDD landen
Nutzung des Hauptspeichers für Zwischenergebnisse fördern fehleranfälligkeit
SQL notwendig, da nicht nur Programmierer die systeme verwenden wollen

Kapitel 3:
Definitionen Haddop, Hive, Spark und Shark(sehr genau)

Kapitel 4:
Installationsbeschreibung
Vergleich mit Hive und anderen verteilten Programmierumgebungen -> Fazit: Spark ist immer schneller

Fazit:
Es fehlen Daten für langen produktiven Einsatz und Skalierung
aber besonders für Hive Nutzer empfehlenswert


---------------------------------------------------------------------
BA Dan

Kapitel 1:
Zielstellung:
	evaluation Hadoop+HBase Speicherung Messdaten
	Eumonis
	schemadesign in HBase


Kapitel 2:
Definitionen: BigData, Cluster, Skalierbarkeit, Transparenz, NoSQL
Hadoop
HBase
Datenmodell: logisch und physisch
Lese- und Schreibpfad
Konsistenzmodell


Kapitel 3:
Datenmodellierung und -migration in HBase
Vergleich zu relationalen Systemen
Datenbeschaffenheit
Anforderungen an die Persistenzschicht der Eumonisplattform
Forderungen des logischen Datenmodells von HBase
HBase Schema- und Tabellendesign
Modellierung der Eumonisdatensätze für Apache HBaseSoftwarearchitektur zur Erstellung von schreibenden Anfragen



Kapitel 4:
Zugriff auf Apache HBase
API
Phoenix framework zur datenabfrage
Evaluation des Rowkey-Design für lesende Anfragen


Kapitel 5:
Zusammenfassung
HBase kann für Szenario verwendet werden
keine Aussage über Performanz möglich

---------------------------------------------------------------------

BA Thurm: Einsatz von NoSQL-Datenbanksystemen für Geodaten

grober Inhalt: NoSQL definition, analyse vorhandener noSQL Systeme und spatial extensions, vorstellung vorhandener implementierungen, allgemeine aussage über eignung von nosql für spatial data

Kapitel 1:
NoSQL orignal im Zusammenhang mit Carlo Strozzi
Big Table Google plus GFS -> Standardserver, verteilt, wachsende Datenmengen
amazon Dynamo
Konferenz in San Francisco -> NoSQL
NoSQL Definition von Stefan Edlich
Skalierung def.
CAP: beschreibende Definition
ACID/BASE
MapReduce: mit Edlich als Quelle

Kapitel 2:
Kategorisierung:
  Key/value:	Beispiel Redis mit Persistenzmodi, verteilt und Datentypen wie List
	        spatial nicht verfügbar (nur binärablage)
  Wide Column Stores:	Big Table, Hadoop und cassandra
			Datenhaltung: Map zeigt auf columns
			Cassandra super column und consitent hashing
			spatial extension nicht vorhanden, Datenhaltung macht es aber möglich (google als vorbild)
  Document stores:	JSON/BSON
			CouchDB mit Maparedue und Mvcc
			 -> Geocouch: GeoJSON, bisher nur bounding box abfragen, GDAL enthalten wodurcj alle simple fesature objekte gespeichert und indexiert werden können
			 Mongodb mit Punktoberationen
graphendatenbanken:	Graphen, wird für semantic web verwendet (RDF und sparql)
			kanten und knoten besitzen mehrere attribute -> datenhaltung: <String, Object>
			strukturiert
			abstriche bei skalierbarkeit
			Neo4j: Tinkerpop graph processing stack für schnitstelle, tinkerpop gremlin oder cypher als traversierungssprache, apache lucene auch für die suche verwendbar
			ACID
			neo4j spatial: basiert auf gis toolkits, gis funktionalität für java, versteht alle ogc simple features und shapefiles
			
Kapitel 3:
Machbarkeit nosql für geodaten

was sind geodaten: strukturen mit raumbezug, vektor oder rasterdarstellung
Datenhaltung: BLOB oder strukturiert(topologie und metrik)
Objektorientierte DBs  bieten vorteile - iso 19107
es muss ein kompromiss aus skalierbarkeit und komplexität gefunden werden
Indexierung: Couchdb mit R-Tree, MOngodb mit Geohash
GeoCouch und neo4j besitzen einzig mehrdimensionalen Index
komplexe geodatentypen in DBs: Indexierung mindestens in 2 Richtungen notwendig, komplexität sollte mit unterstützt werden oder andere vorteile müssen weniger komplexe datenhaltungsmöglichkeiten aufwiegen
key/value oder wide column store nur geeignet wenn sehr große Datenmenge, dokumentbasiert durch multidimensionale abfrage, spatial extension und mapreduce geeigneter, graphbasiert speichert komplex strukturiert
Rasterdaten wichtig, wurden von goolges big table mit wide column store gespeichert


Kapitel 4:
Webpräsenz mit couchdb/geocouch
R-Tree indexierung, punkte und polygone anzeigbar, momentan nur bounding box abfragen


Kapitel 5:
Neo4J Beispiel mit verbunden Punkten und vektordaten des osm
topologische  analyse möglich
OSM Import eingebaut
topologische vorteile gegenüber objektorientierten Datenbanken
BEschreibung der Neo4J Graphen


Kapitel 6:
Zusammenfassung

			
---------------------------------------------------------------------

Taschenbuch Datenbanken

S. 21 
"Ein Datenmodell enthällt drei Bestandteile:
- Datenstrukturen: Objekte und deren Beziehungen (statische Eigenschaften)
- Operationen und Beziehungen zwischen Operationen (dynamische Eigenschaften)
- Integraionsbedingungen auf Objekten und Beziehungen. Dies sind Regeln, die die Menge der erlaubten Zustände bzw. Zustandsübergänge definieren. Sie können modellinhärent sein oder explizit definiert werden."

S. 22
"Ein Datenbankmodell ist ein Datenmodell für ein Datenbanksystem. Es bestimmt. auf welche Art und Weise Daten prinzipiell gespeichert werden und wie man die Daten manipulieren kann."

S. 32
"Ein Informationssystem (IS) dient der rechnergestützten Erfassung, Speicherung, Verarbeitung, Pflege, Analyse, Verbreitung, Übertragung und Anzeige von Informationen. Es ist ein soziotechnisches System, das menschlische und maschinelle Komponenten (Teilsysteme) für die optimale Bereitstellung von Informationen und Kommunikation umfasst."

S. 73
relationales Datenmodell: relation - zeilen=Tupel und Spalten=Attribute

S. 74
"Ein Attribut repräsentiert eine Eigenschaft eines Objekttyps und wird über eine Tabellenspaöte abgebildet."
"Eine Relation ist eine Teilmenge des kartesischen Produktes über den Wertebereich ihrer Attribute. Inhaltlich repräsentiert die Relation eine Menge von Objekten eines Objekttyps."

S. 240
"Das Speichersystem bildet die Speicherstrukturen der internen Satzschnittstelle auf Speicherseiten eines linearen virtuellen Adressraums ab. Aufgabe des Speichersystems ist es somit, die internen Datensätze und Einträge der Zugriffspfade auf Seiten fester Größe einzupassen. Hinzu kommen Operationen zur Verwaltung von Sperren sowie zur Wiederherstellung im Fehlerfall."

S. 243
"Lokalität bezeichnet die Eigenschaft, dass Zugriffe typischerweise auf einen kleineren Bereich der Datenbank bzw. des Externspeichers begrenzt sind."

S. 262
ACID:
Atomarität: Transaktionen sind atomar, wodurch ein Abbruch einer Transaktion deren Operationen rückgängig macht.
Konsistenz: Ende/Abbruch einer Transaktion mit Nachbedingung aller Intergritätsbedingungen
Isolation: Transaktionen verschiedener Benutzer beeinflussen sich nicht gegenseitig
Dauerhaftigkeit: Jede Änderung einer Transaktion ist nach Ende dieser auf die Festplatte geschrieben und nicht mehr im Puffer

S. 284
"Ein Index ist ein Verzeichnis von Dateneinträgen der Form (k, k*), das den effizienten Zugriff auf allen Einträgen mit einem Suchschlüsselwert k erlaubt. Dabei bezeichnet k den Wert eines Suchschlüssels (auch Zugriffsattribut) und k* den Verweis auf den Datensatz in der Datei, der k als Wert des Suchschlüssels enthält."

S. 285
"ein geclusteter Index ist (annähernd) in der gleichen Reihenfolge sortiert wie die Datei, auf die der Index verweist."

S. 285 f
"ein dicht besetzter Index(dense index) enthält enthällt für jeden Suchschlüsselwert, der in einem Datensatz der Datei vorkommt, (mindestens) einen Dateneintrag..."

S. 286
"Ein dünn besetzter Index (sparse Index) speichert nicht für jeden Suchschlüsselwert einen Eintrag im Index."

S. 287
ISAM: index-sequential access method, Grundlage ist eine sortierte Datei, neue Datei mit Index zu jeder Seite der Originaldatei einen Eintrag (mit dem ersten Schlüsselwert auf dieser Seite), auch Baumstruktur möglich (Blätter enthalten Dateneinträge und verweisen jeweils auf die Datenseite die als erste einen Satz mit dem Suchschlüsselwert k in der Hauptdatei enthält), statisch, effektiv wenn die Datei nicht häufig geändert wird, Überlaufseiten ergänzen Blattseiten um neue Dateneinträge, lange Ketten von Überlaufseiten mindern performanz von suchoperationen, häufige inserts oder deletes sind ungeeignet und erfordern oft eine Reorganisation

S. 288
B-Baum: "Der B-Baum ist ein dynamisch balancierter Indexbaum, bei dem jeder Indexeintrag auf eine Seite der Hauptdatei zeigt.", Höhe h und Ordnung m, Eigenschaften: "1. Jeder Weg von der Wurzel zum Blatt hat die Länge h (balanciert) 2. Jeder Knoten enthält mindestens m Elemente (außer der Wurzel) und  höchstens 2m Elemente (mindestens halbvolle Belegung) 3. Jeder Knoten ist entweder eine Blattseite oder hat höchstens 2m + 1 Kinder (maximale Belegung)", garantierte minimale Belegung von 50%, h beschreibt die Anzahl der Seitenzugriffe  als relevantes Maß für die Zugriffskosten, n Datensätze: Zugriff in maximal logm(n) Seitenzugriffen
B+-Baum: Dateneinträge aussschließlich in Blattknoten, Blattknoten unidirektional verkettet, Ordnung ist hier (m -> Mindestbelegung für Indexseiten, m* -> Mindestbelegung der Blattseiten)

S. 289
Bulk Loading:  großer Datensatz wird sortiert und anschließend ein B-Baum aufgebaut

S. 290
digitale Bäume: Verfahren, mit Schlüsselwerten von Zeichenketten aus einem festen Alphabet, lexikografische Ordnung, nicht ausgeglichen, Vorteil ist das keine kompletten Schlüssel gespeichert werden müssen

S. 291
Hashing: Hashfunktion ordnet Speicherbereich (Bucket) einen Wert zu sodass ein direkter Zugriff möglich ist, erweitertes hashing  stellt eine dynamische Hashfunktion zur Verfügung (index wird dynamisch angepasst)

S. 296
"Die gemeinsame Speicherung von Datensätzen, die in typischen Anfragen zusammen benötigt werden, wird als Clustering bezeichnet."
clusering: setzt Indeystruktur vorraus, kann nach Schlüsselattributen oder Fremdschlüsselattributen erfolgen
"Bei der Partitionierung wird eine Relation in disjunkte Partitionen aufgeteilt, die auf verschiedenen Platten gespeichert werden."

S. 297
Partitionierung: Vorteile: Anfrageoptimierung durch auslasten der Partitionen; Vereinfachung der Administration der Partitionen; Paralelle Verarbeitung,
				 Bereichspartitionierung, Round-Robin-Partitionierung, Hash-Partitionierung
				 
S. 333
"Die Begriffe Benchmark (Maßstab) bzw. Benchmarking (Maßstäbe setzen) bezeichnen ein formalisiertes Konzept, um Verbesserungsmöglichkeiten durch Gegenüberstellung von Leistungsmerkmalen mehrerer vergleichbarer Objekte, Prozesse oder Programme zu finden."
Benchmarkingergebnisse= Durchsatzwert und Preis-/Leistungsverhältniss

TPC hat Benchmarks definiert: TPC-D wäre gut

S. 394 ff.
"Bei einem Mehrrechner-Datenbanksystem (MDBS) werden die Datenbankverwaltungsfunktionen auf mehreren Prozessoren bzw. Rechnern ausgeführt."
MDBS shared everything: ein DBMS auf eng gekoppelten Multiprozessor-Rechnerumgebung
     shared Nothing: Verarbeitung durch mehrere Rechner mit jeweils einem DBMS (Externspeicher ist unter den beteiligten Rechnern partitioniert)
	 shared disk: mehrere lokal angeordnete, lose oder nah gekoppelte Rechner mit je einem DBMS und einer gemeinsamen Speicherzuordnung
	 Lokal verteilte Systeme werden als parallele Datenbanksysteme bezeichnet

S. 398
"Verteilte Datenbanksysteme (VDBS) sind geografisch verteilte Shared-Nothing Systeme mit homogenen lokalen DBMS, die gemeinsam ein globales konzeptionelles DB-Schema unterstützen.
Förderierte Datenbanksysteme (FDBS) sind ebenfalls geografisch verteilte Sgated nothing systeme, wobei die beteiligten lokalen DBMS eine höhere Autonomie aufweisen, d.h. dass jeweils eine eigene lokale Datenbank mit lokalem DB-schema vorliegt."

S. 404
"Zuverlässigkeit entspricht der Wahrscheinlichkeit, dass das System zu einem bestimmten Zeitpunkt läuft;
Verfügbarkeit ist die Wagscheinlichkeit, dass während einer bestimmten Zeitdauer ein Zugriff möglich ist."

S. 497
"Geoobjekte ((geographic)features) besitzen eine ausgezeichnete geometrische Eigenschaft, auf die sich räumliche Anfragen und Operationen beziehen. Daneben können sie weitere (geometrische und nicht geometrische) Eigenschaften aufweisen. Geoobjekte dienen der Beschreibung von Objekten oder Phänomenen der realen Welt, die einen Lagebezug zur Erde aufweisen."
"Topologische Eigenschaften dienen zur Beschreibung der relativen räumlichen Beziehungen von Geoobjekten zueinander, wobei von der Geometrie abstrahiert wird."

S. 500
ISO 19107: spatial schema, beschreibt geometrische Objekte und Eigenschaften sowie deren Beziehungen

S. 502
"Simple Features sind Geometrien im zweidimensionellen Raum, deren Stützpunkte geradlinig verbunden sind."

S. 506
"Räumliche Bezugssysteme (spatial reference systems) erlauben die Interpretation der gespeicherten Koordinaten als Beschreibung von Lage- und Ausdehnungsinformationen in einem (realen) Datenraum. Ein räumliches Bezugssystem besteht aus einem Koordinatensystem (coordinate system), einem Geltungsbereich und Angaben, die es erlauben, Daten aus unterschiedlichen Koordinatensystemen auf ein globales System abzubilden."

S. 509ff
geometrische funktionen wie intersection
topologische Prädikate (innere und äußere Ränder -> charakterisierung)
Operationen mit topologischen prädikaten möglich (matrix mit wahrheitswerten)

S. 516
mehrstufige Anfragebearbeitung

S. 517
"Räumliche Indexe (Spatial Access Methods, SAM) dienen dazu, die Kandidaten zu bestimmen, die potentiell eine Anfragebedingung erfüllen."

S.518
anforderungen an räumliche Indexstrukturen:
	Approximationen sind zu verwalten
	effiziente ausführung -> benachbarte daten auch im selben Datenbankblock
	einfügen und löschen und update darf die effizienz kaum verändern
	gute speicherplatzauslastung
	speicherplatzauslastung und Bearbeitungszeit unabhängig von Ungleichverteilung der Geoobjekte
	
S. 519
"Clipping ordnet ein Geoobjekt bzw. dessen Approximation jeder Blockregion zu, die es schneidet."
Punkttransformation: Überführung k-dimensionaler Rechtecke in 2k-dikmensionelle Punkte

S. 520
fraktale Kurven

S. 521ff
Quadtrees: "sind räumliche Datenstrukturen, die einen k-dimensionalen Datenraum rekursiv in 2^k gleich große Zellen unterteilen."
			lineare quadtrees: abbildung quadtree in 1-dimensionalen raum -> Indexstruktur (B+ Baum)
			Datenraumbeszogener lieare quadtree: Quadtree-zellen in Z-Werten mit indexstruktur
			Datenbezogene lineare quadtrees: approximieren der geometrien durch eine oder mehrere Quadtree-Zellen, wieder Z-werte und indexstruktur
			
S. 523ff
R-Bäume: "organisieren k-dimensionale Rechtecke mithilfe überlappender Blockregionen", balancierte bäume,
		Verzeichnissknoten: Tupel (ref, mur), ref ist Verweis auf direkten Nachfahren, mur ist minimal umgebende Rechteck alle Rechtecke der Kindknoten
		Datenknoten: mor ist das eigentliche geoobjekt
		
R*-Bäume: neue einfügeoperation welche den baum schrittweise organisiert

--------------------------------------------------------------------------------------------------
MA Untersuchung von Techniken verteilter Datenbanksysteme zur Speicherung und Abfrage von räumlichen Daten, Jörn Ahlers

Kapitel 1:
Vorstellung Postgre und postgis und oracle 11g und ESXI(Virtualisierungssoftware)


Kapitel 2:
ausführliche Definitionen: verteilte Systeme, Datenbanken, verteilte DB, parallele DB, Replikationsverfahren


Kapitel 3:
verteilte Geodatenbanksysteme
homogene prä-integrierte Datenbanksysteme, heterogene prä-integrierte Datenbanksysteme, post-integrierte Geodatenbanksysteme, Parallele Geodatenbanksysteme


Kapitel 4:
PostgreSQL
Grundlagen, Installation, Pgpool


Kapitel 5:
Oracle DB
Grundlagen, Installation


Kapitel 6:
Zusammenfassung

--------------------------------------------------------------------------------------------------

MapReduce: Simpliﬁed Data Processing on Large Clusters

--------------------------------------------------------------------------------------------------

Basiswissen Softwarearchitektur

S.71
Einflussfaktoren wirken auf den Entwurf von Softwarearchitekturen ein.

S. 74 ff.
3 Arten von Einflussfaktoren: organisatorische, technologische und produktfaktoren
organisatorische: schwer zu ändern; Ursprung in Organisation des Unternehmens; Unterteilung nach Hofmeister: Management, Mitarbeiter, Prozess- und Entwicklungsumgebung, Entwicklungszeitplan und Entwicklungsbudget
technologische: Hard- und Softwaretechnologien und Standards die zum Einsatz kommen; Hofmeister: Hardware, Softwaretechnologien, Architekturtechnologien und Standards
produktfaktoren: funktionalen und nicht funktionale Anforderungen and die Software; Liste: funktionale Anforderungen, Benutzerschnittstelle, Leistung, Zuverlässigkeit, Fehlererkennung und Dienste, Änderbarkeit, Testbarkeit

S. 171
allgemeines Vorgehen der Architekturbewertung:
"Bewertungskriterien festlegen [wichtigsten Risiken aus der Spezifikation der Einflussfaktoren]
 Messbarkeit der Kriterien sicherstellen
 Bewertungsarten und Methoden festlegen
 Durchführen der Bewertung
 Zusammensetzen der Ergebnisse und Maßnahmen ergreifen"
 
S. 172
Bewertungsarten:
"Umfangreiches, szenariobasiertes Assessment
 Discovery Review
 Gezielte Überprüfung
 Ad-hoc-Bewertung"
 
S. 175
Qualitative  Techniken: umfassen Fragetechniken wie szenariobasierte  Bewertung, Fragebögen und Checklisten; zur Bewertung jeder Art von Faktoren; Gedankenexperiment zum zukünftigen Verhalten
Quantitative Techniken: Simulation, Prototypen, Metriken und math. Modelle; Aussagen über spezifische Fragen; adressieren spezielle Qualitätsmerkmale wie Laufzeit



--------------------------------------------------------------------------------------------------


Lehrbuch der Software-Technik

S. 258 ff.
Qualitätsmerkmale: 
				unterteilung in Kriterien/Teilmerkmale
				nach DIN 9126 geregelt (wurde durch ISO/IEC 25000 ersetzt, jedoch propriätär)
					Funktionalität(Richtigkeit, Angemessenheit, Interoperabilität, Ordnungsmäßigkeit, Sicherheit), Zuverlässigkeit(Reife, Fehlertoleranz, Wiederherstellbarkeit), Benutzbarkeit(Verständlichkeit, Erlernbarkeit, Bedienbarkeit), Effizienz(Zeitverhalten, Verbrauchsverhalten), Änderbarkeit(Analysierbarkeit, Modifizierbarkeit, Stabilität, Prüfbarkeit), Übertragbarkeit(Anpaßbarkeit, Installierbarkeit, Konformität, Austauschbarkeit) <- Merkmale aus DIN, kriterien aus Buch


--------------------------------------------------------------------------------------------------

Software Engineering

S. 63
Qualität: DIN 55350-11 1995-08: Geamtheit von Eigenschaften und Merkmalen eines Produktes oder einer Tätigkeit, die sich auf die Eignung zur Erfüllung gegebener Erfordernisse beziehen.


S. 446
"Ein systematischer Test ist ein Test, bei dem
die Randbedingungen definiert oder präzise erfasst sind,
die Eingaben systematisch ausgewählt wurden,
die Ergebnisse dokumentiert und nach Kriterien beurteilt werden, die vor dem Test festgelegt wurden."

S. 455
Testdefinition nach Grundlage
"Werden die Testfälle auf Basis der in der Spezifikation geforderten Eigenschaften des Prüflings ausgewählt (z.B. Funktionalität, Antwortzeit), dann spricht man von einem Block-Box-Test oder auch von einem Funktionstest (19.5).
Berücksichtigt man bei der Wahl der Testfälle die innere Struktur des Prüflings und die (durch spezielle Werkzeuge erstellten) Aufzeichnungen früherer Programmläufe, dann handelt es sich um einen Glass-Box-Test oder Struktur-Test (19.6)."

S. 456
Testklassifikation nach Aufwand

S. 457
Testklassifikation nach Komplexität des Prüflings
f. Testklassifikation nach getesteter Eigenschaft

S.458
Testklassifikation nach beteiligten Rollen

S. 471
"Ein umfassender Black-Box-Test sollte
alle Funktionen des Programms aktivieren (Funktionsüberdeckung),
alle möglichen Eingaben bearbeiten (Eingabeüberdeckung),
alle möglichen Ausgabeformen erzeugen (Ausgabeüberdeckung),
die Leistungsgrenzen ausloten,
die spezifizierten Mengengrenzen ausschöpfen,
alle definierten Fehlersituationen herbeiführen."

S. 278 f.
IEEE Std 610.12: metric - A quantitative measure of the degree to which a system, component, or peocess possesses a given attribute.
				 quality metric - a) dito
								  b) A function whose inputs are software data and whose output is a single numerical value that can be interpreted as the degree to which the software possess a giben quality attribute.
Kostenmetriken, Fehlermetriken,  Volumens- und Umfangsmetriken und Qualitätsmetriken

S.280
Anforderungen an Metriken: differenziert, vergleichbar, reproduzierbar, verfügbar, relevant, rentabel und plausibel

S.283
Metrikarten
objektive Metrik: Messunf, Zählung, evtl. auch Normierung
subjektive Metrik: Beurteilung durch Begutachter, verbal oder auf vorgegebener Skala
Pseudometrik: Berechnung (auf Basis von Messungen und/oder Beurteilungen)



--------------------------------------------------------------------------------------------------

Leistungsanalyse paralleler Programme

S. 20
Quantifizierung einer Eigenschaft eines Systems = Leistungsindex
Kesselman: Leistung=gewichtete Summation von Leistungsindizes
McKerrow: Leistung=gewichtete Summation der Leistung bzgl. der einzelnen Leistungsindizes

S. 21
Speedup=Verhältnis der Ausführungszeiten zwischen der auf N Prozessoren ausgeführten parallelen Version eins Programms und der sequentiellen Version des Programmes
Effizienz=Verhältnis des Speedups zur Anzahl der verwendeten Prozessoren

S.24
"Benchmarking ist eine Methode der Analyse des Leistungsverhaltens von Rechensystemen anhand von Referenzprogrammen oder Sätzen von Referenzprogrammen (Benchmarks). Dabei wird das Leistungsverhalten verschiedener Rechensysteme in Relation gesetzt, um so Vergleichskriterien  für Rechensysteme zu erhalten."

S. 28
"Unter Leistungsmessung versteht man die Beobachtung des Ablaufverhaltens eines Programms bei der Ausführung auf einem realen System. Das Ziel das dabei verfolgt wird, ist die Gewinnung von Erkenntnissen, die zur Optimierung eines Programms genutzt werden können."
Verzögerungs-, Nutzungs- und Auslastungsindizes

S. 59
"Software-Monitore arbeiten ohne dedizierten Hardware. Sie teilen sich die Hardware-Ressourcen mit dem beobachteten Programm; dadurch ist eine Beeinflussung des beobachteten Programmablaufs unvermeitlich."

S. 64
Stichprobenverfahren:  statistisches verfahren; in gleichmäßigen Zeitabständen Befehlszähler  aufzeichnen; Qualität hängt an Frequenz und unabhängigkeit der Messung

--------------------------------------------------------------------------------------------------

spatial databases - gis


=======
Objektorientierte Datenbanksysteme

S. 58 ff.
Leitfaden zur Auswahl eines ODBMS
Schritte: Vorauswahl(beschränkung auf wenige Systeme; grobe wichtige Kriterien verwenden), Funktionale Evaluierung(Anforderungskatalog; ausführliche evaluierung; ), Benchmarks(bestehender benchmarks geben allgemeine und alte aussage und sind somit nicht geeignet -> eigene Benchmarks; Benchmarks als Prototyp der zukünfitgen Anwendung; nur Ausschnitte aus Anwednungsprogramm; testen umfang und Leistungsfähigkeit; ), Planung und Aufwand

S. 66
Nichttechnische Kriterien: Marktposition, Preis, Produktplanung, Referenzkunden, Service&SUpport, Standards

Anhang C: Checkliste S. 233 ff.
Herstellerfirma und Produkt: Marktposition, Preis, Produktplanung, Support, Standards und Zertifizierunng
Objektmodell und Objektzugriff: vordefinierte Basistypen bzw. Komplexe Objekte, Methoden (im Zusammenhang mit Datentypen), Wertdefinierte Schlüssel(eigene Schlüssel und deren Management)
Schemaevolution: Schemaänderungen, Migration, Schemaversionierung
Architektur: Plattformen, Hardware-Andorderungen, Cliemt/Server Konfiguration, Heterogenität, Clustering, Tuning, Verteilung
Zugriffssynchronisation: ACID, Transaktionsmechanismen, SPerrenverwaltung, Synchronisationsverhalten(optimistisch oder pessimistisch), Recovery
Workgroup Computing: Versionierung, change notification
Assoziative Anfragen: funktionalität, Schnittstellen, Anfrageoptimierung
Sprachschnittstellen: Sprachschnittstellen, Interoperabilität(der Schnittstellen)
Zugriffsschutz: Zugriffsrechte
Werkzeuge: allgemeine tools wie query tool, Werkzeuge zur Applikationsentwicklung, Werkzeuge zur Datenbankadministration
24/7 Betrieb: Werkzeuge im Online Betrieb, AUsfallsicherheit